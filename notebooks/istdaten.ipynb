{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connect to Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%local\n",
    "import os\n",
    "username = os.environ['JUPYTERHUB_USER']\n",
    "get_ipython().run_cell_magic('configure', line=\"-f\", cell='{ \"name\":\"%s-final-istaden\", \"executorMemory\":\"4G\", \"executorCores\":4, \"numExecutors\":10, \"driverMemory\": \"4G\" }' % username)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%send_to_spark -i username -t str -n username"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark.sql.functions as F\n",
    "\n",
    "# Visualizing delay distributions\n",
    "import matplotlib\n",
    "matplotlib.use('agg')\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (30,8)\n",
    "plt.rcParams['font.size'] = 12\n",
    "plt.style.use('fivethirtyeight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.orc('/data/sbb/orc/istdaten')\n",
    "df = df.selectExpr(  'betriebstag as date',\n",
    "                     'produkt_id as transport_type',\n",
    "                     'haltestellen_name as stop_name',\n",
    "                     'ankunftszeit as arrival_scheduled',\n",
    "                     'an_prognose as arrival_actual',\n",
    "                     'an_prognose_status as delay_type',\n",
    "                     'durchfahrt_tf as stop_skip',\n",
    "                     'bpuic as stop_id',\n",
    "                     'linien_text as line_name',\n",
    "                     'verkehrsmittel_text as line_type',\n",
    "                     'linien_id as line_id'\n",
    "                  )\n",
    "\n",
    "# Reachable stops with a 15km radius of Zurich HB\n",
    "reachable_stops_path = \"/user/%s/final/parquet/reachable_stops\" %username\n",
    "stop_id_reachable = spark.read.parquet(reachable_stops_path)\n",
    "stop_id_reachable = stop_id_reachable.withColumn(\"stop_id\",F.split(stop_id_reachable.stop_id,':')[0]).drop(\"stop_name\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep only rows where measured time of arrival is \"GESCHAETZT\" \n",
    "df = df.filter('an_prognose_status = \"GESCHAETZT\"')\n",
    "\n",
    "# convert day of the trips between\n",
    "df = df.withColumn('date', F.to_timestamp('date', \"dd.MM.yyyy\"))\n",
    "df = df.withColumn('arrival_scheduled', F.to_timestamp('arrival_scheduled', \"dd.MM.yyyy HH:mm\"))\n",
    "df = df.withColumn('arrival_actual', F.to_timestamp('arrival_actual', 'dd.MM.yyyy HH:mm:ss'))    \n",
    "\n",
    "# keep only rows for stops that are not skipped\n",
    "df = df.filter(df.stop_skip == False)\n",
    "\n",
    "# keep only rows for stops during the week\n",
    "df = df.withColumn(\"day_of_week\",F.dayofweek(df.date))\n",
    "df = df.filter(df.day_of_week.between(2,6))\n",
    "\n",
    "# hours between 8am and 8pm\n",
    "min_day_hour, max_day_hour = 8, 20\n",
    "df = df.filter(F.hour(F.col('arrival_scheduled')).cast('int').between(min_day_hour, max_day_hour))\n",
    "\n",
    "# only keep stops within the 15km radius\n",
    "df = df.join(stop_id_reachable,on=\"stop_id\")\n",
    "\n",
    "# add hour column\n",
    "df = df.withColumn(\"hour\",F.hour(F.col(\"arrival_scheduled\")))\n",
    "\n",
    "# Remove the rows where transport_type is null\n",
    "df = df.where((F.col(\"transport_type\")==\"Tram\") | (F.col(\"transport_type\")==\"Zug\") | (F.col(\"transport_type\")==\"Bus\")).cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computing Delays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to remove negative delays\n",
    "@F.udf\n",
    "def relu(x):\n",
    "    return max(x, 0)\n",
    "\n",
    "df = df.withColumn(\"delay\", relu((F.col(\"arrival_actual\").cast(\"long\") - F.col(\"arrival_scheduled\").cast(\"long\"))))\n",
    "df = df.where(~(F.col('delay').isNull())).cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# statistics type of transport average delays\n",
    "transport_avg_delays = df.groupby(\"transport_type\").agg(F.mean('delay')).cache()\n",
    "transport_avg_delays = transport_avg_delays.withColumnRenamed(\"avg(delay)\", \"avg_delay\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "# Plot transport average delays\n",
    "\n",
    "t_avg_delays_plot = transport_avg_delays.toPandas()\n",
    "\n",
    "plt.bar(x=t_avg_delays_plot.transport_type, height=t_avg_delays_plot.avg_delay)\n",
    "# transport_avg_delays[\"avg_delay\"].plot.bar\n",
    "plt.xlabel('average delay distribution by train')\n",
    "plt.ylabel('average delay (seconds)')\n",
    "plt.xticks(range(len(t_avg_delays_plot)), t_avg_delays_plot.transport_type)\n",
    "\n",
    "%matplot plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hour_avg_delays = df.groupby(\"hour\").agg(F.mean('delay')).cache()\n",
    "hour_avg_delays = hour_avg_delays.withColumnRenamed(\"avg(delay)\",\"avg_delay\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot transport average delays\n",
    "plt.cla()\n",
    "h_avg_delays_plot = hour_avg_delays.toPandas().sort_values(by=\"hour\").reset_index(drop=True)\n",
    "\n",
    "plt.bar(x=h_avg_delays_plot.hour, height=h_avg_delays_plot.avg_delay, color=(0.2, 0.4, 0.6, 0.6))\n",
    " \n",
    "plt.xlabel('average delay distribution by hour')\n",
    "plt.ylabel('average delay (seconds)')\n",
    "plt.xticks(h_avg_delays_plot.hour)\n",
    "\n",
    "# Show the graph\n",
    "%matplot plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# More to less general cases\n",
    "default = df.select(F.mean('delay').alias('avg_delay')).cache()\n",
    "t_type_line = df.groupBy('transport_type', 'line_name').agg(F.mean('delay').alias('avg_delay')).cache()\n",
    "t_type_line_hour = df.groupby(\"transport_type\", \"line_name\", \"hour\").agg(F.mean('delay').alias('avg_delay')).cache()\n",
    "t_type_line_hour_stop = df.groupby(\"transport_type\", \"line_name\", \"hour\", \"stop_id\").agg(F.mean('delay').alias('avg_delay')).cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the avg delays found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "default.write.mode('overwrite').parquet('/user/%s/final/parquet/default' % username)\n",
    "t_type_line.write.mode('overwrite').parquet('/user/%s/final/parquet/t_type_line' % username)\n",
    "t_type_line_hour.write.mode('overwrite').parquet('/user/%s/final/parquet/t_type_line_hour' % username)\n",
    "t_type_line_hour_stop.write.mode('overwrite').parquet('/user/%s/final/parquet/t_type_line_hour_stop' % username)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark",
   "language": "python",
   "name": "pysparkkernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "python",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "pyspark",
   "pygments_lexer": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
