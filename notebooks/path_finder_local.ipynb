{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from notebook import notebookapp\n",
    "from IPython.display import Markdown as md\n",
    "\n",
    "servers = list(notebookapp.list_running_servers())\n",
    "s = servers[0]['base_url'][1:] + 'voila/render/notebooks/path_finder_local.ipynb'\n",
    "\n",
    "md(\"<b>Voila rendering of this notebook can be found through the link below.</b><br>[link](/{}).\".format(s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from hdfs3 import HDFileSystem\n",
    "import os\n",
    "username = os.environ['JUPYTERHUB_USER']\n",
    "username = 'hadidane'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data from HDFS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdfs = HDFileSystem(user='ebouille') # impersonate ebouille to read the file\n",
    "def read_hdfs(path):\n",
    "    files = hdfs.glob(path)\n",
    "    df = pd.DataFrame()\n",
    "    for file in files:\n",
    "        with hdfs.open(file) as f:\n",
    "            df = df.append(pd.read_parquet(f))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "walking_edges = read_hdfs('/user/%s/final/parquet/walking_edges/*.parquet' % username)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transport_edges = read_hdfs('/user/%s/final/parquet/transport_edges/*.parquet' % username)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reachable_stops = read_hdfs('/user/%s/final/parquet/reachable_stops/*.parquet' % username)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "routes = read_hdfs('/user/%s/final/parquet/routes/*.parquet' % username)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "walking_edges['value'] = list(zip(walking_edges['end_vertex'], walking_edges['duration']))\n",
    "walking_edges = walking_edges.groupby('start_vertex').agg({'value': set})\\\n",
    "                             .to_dict()['value']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shortest Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function assumes a (spark) dataframe with columns 'start_vertex', 'end_vertex', 'start_time', 'duration', 'route_id' \n",
    "# edges is a dataframe that represents the edges of the graph, \n",
    "# end_time should be in minutes\n",
    "def latest_departure_paths(edges, end_stop, end_time, walking_edges):\n",
    "\n",
    "    def edge_valid(u, v, time, dur, route_id): \n",
    "        next_edges = all_roads.get(v, [])\n",
    "        \n",
    "        # Did we reach the destination ?\n",
    "        if v == end_stop and time + dur <= end_time: \n",
    "             return (time, v, route_id, dur)\n",
    "        \n",
    "        if u != end_stop and v != end_stop:\n",
    "            for edge in next_edges[::-1]: # Traverse the list in reverse order because it's sorted by descending starting time\n",
    "                time_v, next_v, route_id_v, dur_v = edge\n",
    "                if (route_id == route_id_v and time + dur <= time_v) or (time + dur + transfer_time <= time_v): \n",
    "                    return (time, v, route_id, dur)            \n",
    "            \n",
    "            # Can we walk from v instead?\n",
    "            for end_vertex, walking_duration in walking_edges.get(v, []):\n",
    "                if end_vertex != u: # do not loop back to u\n",
    "                    for next_next_edge in all_roads.get(end_vertex, []):\n",
    "                        time_next = next_next_edge[0]\n",
    "                        if time + dur <= time_next - walking_duration - transfer_time : # can we make in time to v in order to walk\n",
    "                            return (time, v, route_id, dur)\n",
    "                \n",
    "        return None\n",
    "                \n",
    "    transfer_time = 2 # at least 2 minutes to transfer\n",
    "    \n",
    "    all_roads = {}\n",
    "    start_time = end_time - 120 # look only at edges departing at most 2 hours before end_time\n",
    "    \n",
    "    all_roads[end_stop] = [(end_time, end_stop, '', 0)]\n",
    "    \n",
    "    edges = edges[(edges['start_time'] >= start_time) & (edges['start_time'] <= end_time)].sort_values(by=['start_time'], ascending=False).to_numpy()\n",
    "\n",
    "    for row in edges:\n",
    "        start_vertex, end_vertex, start, duration, route_id = row[:5]\n",
    "        update = edge_valid(start_vertex, end_vertex, start, duration, route_id)\n",
    "        if update:\n",
    "            if start_vertex in all_roads:    \n",
    "                all_roads[start_vertex].append(update)\n",
    "            else:\n",
    "                all_roads[start_vertex] = [update]\n",
    "                        \n",
    "    return all_roads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import groupby\n",
    "import numpy as np\n",
    "\n",
    "# Journey reconstruction\n",
    "\n",
    "# Returns a List of all possible edges that can be taken after edge 'edge'\n",
    "def select_next(all_roads, walking_edges, edge, transfer_time=2):\n",
    "    \n",
    "    prev_time, node, prev_route_id, prev_duration = edge[:4]\n",
    "    next_edges = all_roads.get(node, [])\n",
    "    \n",
    "    if prev_route_id == 'Walking': \n",
    "        # A walking edge encodes only one next trip at the node, stored as an index of the trip in all_roads[node] \n",
    "        return [next_edges[edge[-1]]]\n",
    "    else:\n",
    "        possible_edges = []\n",
    "        # We may take a transport edge or a walking edge in this case\n",
    "        next_edges = next_edges +  get_walking_edges(all_roads, walking_edges, node)\n",
    "        min_departures = {}\n",
    "        for edge_n in next_edges:\n",
    "            t, v, route_id, dur = edge_n[:4]\n",
    "            if route_id == 'Walking' and prev_time + prev_duration <= t:\n",
    "                possible_edges.append(edge_n)\n",
    "            elif prev_route_id == route_id and prev_time + prev_duration <= t:\n",
    "                if (route_id, v) in min_departures and  min_departures[(route_id, v)][0] > t :\n",
    "                    min_departures[(route_id, v)] = edge_n\n",
    "                elif route_id not in min_departures:\n",
    "                    min_departures[(route_id, v)] = edge_n\n",
    "            elif prev_route_id != route_id and prev_time + prev_duration + transfer_time <= t:\n",
    "                possible_edges.append(edge_n)\n",
    "        possible_edges += min_departures.values()\n",
    "\n",
    "        return possible_edges \n",
    "\n",
    "# Recursively iterate on all possible paths to the destination, and yield journeys as we find them \n",
    "def iterate_all_edges(all_roads, walking_edges, start_edges, end_stop, end_time, cur_journey):\n",
    "    for edge in start_edges:\n",
    "        t, v, route_id, dur = edge[:4]\n",
    "        if v == end_stop and t + dur <= end_time: # have we reached the destination?\n",
    "            yield cur_journey + [edge]\n",
    "        elif v != end_stop:\n",
    "            next_edges = select_next(all_roads, walking_edges, edge)\n",
    "            \n",
    "            for journey in iterate_all_edges(all_roads, walking_edges, next_edges, end_stop, end_time, cur_journey + [edge]):\n",
    "                yield journey\n",
    "                \n",
    "# Compute the number of transfers as well as the total walking duration for a Journey\n",
    "def get_journey_attributes(journey):\n",
    "    walking_distance = sum([t[-2] for t in journey if t[2] == 'Walking'])\n",
    "    transfers = len(set([t[2] for t in journey if t[2] != 'Walking']))\n",
    "    return [transfers, walking_distance]\n",
    "\n",
    "# Compute viable walks starting at node start_stop\n",
    "# A walking edge u -> v holds information about the single trip to take from v\n",
    "# This avoids unnecessary path computations\n",
    "def get_walking_edges(all_roads, walking_edges, start_stop, transfer_time=2):\n",
    "    possible_walking_edges = []\n",
    "    for end_vertex, duration in walking_edges.get(start_stop, []):\n",
    "        \n",
    "        for index, edge in enumerate(all_roads.get(end_vertex, [])):\n",
    "            time_next, node_next = edge[:2]\n",
    "            if node_next != start_stop:\n",
    "                possible_walking_edges.append((time_next - duration - transfer_time, end_vertex, 'Walking', duration, index))\n",
    "    return possible_walking_edges\n",
    "    \n",
    "def generate_best_paths(all_roads, walking_edges, start_stop, end_stop, end_time):\n",
    "    # add possible paths that start by walking\n",
    "    start_edges = all_roads.get(start_stop, []) + get_walking_edges(all_roads, walking_edges, start_stop)\n",
    "    if not start_edges: # not paths were found\n",
    "        yield []\n",
    "    else:\n",
    "        # sort edges and group by start_time\n",
    "        start_edges = sorted(start_edges, key=lambda x:x[0], reverse=True)\n",
    "        start_edges = groupby(start_edges, key=lambda x:x[0])\n",
    "        for start_time, edges in start_edges:\n",
    "            # find all possible journeys that start at time start_time\n",
    "            all_journeys = list(iterate_all_edges(all_roads, walking_edges, list(edges), end_stop, end_time, []))\n",
    "            journey_attribs = np.array([get_journey_attributes(journey) for journey in all_journeys])\n",
    "            sorted_indices = np.lexsort(journey_attribs.T)\n",
    "            for i in sorted_indices:\n",
    "                yield all_journeys[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Processes a list of edges (Journey) into a list of segments\n",
    "def journey_to_segments (journey, start_stop):\n",
    "    \n",
    "    grouped_journey = [(route_id, list(edges)) for (route_id, edges) in  groupby(journey, lambda x: x[2])]\n",
    "    segments = []\n",
    "    for index, (route_id, edges) in enumerate(grouped_journey):\n",
    "        \n",
    "        start_time_s = edges[0][0]\n",
    "        \n",
    "        if route_id == 'Walking' and index > 0:\n",
    "            # Start walking as soon as you get to the previous stop\n",
    "            start_time_s = segments[-1][4] + segments[-1][5]\n",
    "             \n",
    "        end_stop_s = edges[-1][1]\n",
    "        duration_s = edges[-1][0] + edges[-1][3] - edges[0][0]\n",
    "        \n",
    "        start_stop_s = start_stop if index == 0 else segments[index - 1][2]\n",
    "            \n",
    "        stops_s = [start_stop_s] + [t[1] for t in edges]\n",
    "                \n",
    "        segments.append((index + 1, start_stop_s, end_stop_s, route_id, start_time_s, duration_s, stops_s))\n",
    "            \n",
    "    return segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lookup dicts for human readable information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_id_to_stop_dict = reachable_stops[['stop_id', 'stop_name']].set_index('stop_id').to_dict()['stop_name']\n",
    "stop_id_to_lon_dict = reachable_stops[['stop_id', 'stop_lon']].set_index('stop_id').to_dict()['stop_lon']\n",
    "stop_id_to_lat_dict = reachable_stops[['stop_id', 'stop_lat']].set_index('stop_id').to_dict()['stop_lat']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "routes['route_name'] = routes['route_desc'] + ' ' + routes['route_short_name']\n",
    "route_id_to_route_name_dict = routes[['route_id', 'route_name']].set_index('route_id').to_dict()['route_name']\n",
    "route_id_to_route_name_dict['Walking'] = 'Walk'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### delayyyssss\n",
    "#read_hdfs('/user/%s/final/parquet/transport_edges/*.parquet' % username)\n",
    "train_types = read_hdfs('/user/%s/final/parquet/train_types/*.parquet' % username)\n",
    "bus_types = read_hdfs('/user/%s/final/parquet/bus_types/*.parquet' % username)\n",
    "tram_types = read_hdfs('/user/%s/final/parquet/tram_types/*.parquet' % username)\n",
    "train_types_hour = read_hdfs('/user/%s/final/parquet/train_types_hour/*.parquet' % username)\n",
    "bus_types_hour = read_hdfs('/user/%s/final/parquet/bus_types_hour/*.parquet' % username)\n",
    "tram_types_hour = read_hdfs('/user/%s/final/parquet/tram_types_hour/*.parquet' % username)\n",
    "train_types_stops = read_hdfs('/user/%s/final/parquet/train_types_stops/*.parquet' % username)\n",
    "bus_types_stops = read_hdfs('/user/%s/final/parquet/bus_types_stops/*.parquet' % username)\n",
    "tram_types_stops = read_hdfs('/user/%s/final/parquet/tram_types_stops/*.parquet' % username)\n",
    "\n",
    "train_types[\"type_vehicle\"] = \"Train\"\n",
    "bus_types[\"type_vehicle\"] = \"Bus\"\n",
    "tram_types[\"type_vehicle\"] = \"Tram\"\n",
    "train_types_hour[\"type_vehicle\"] = \"Train\"\n",
    "bus_types_hour[\"type_vehicle\"] = \"Bus\"\n",
    "tram_types_hour[\"type_vehicle\"] = \"Tram\"\n",
    "train_types_stops[\"type_vehicle\"] = \"Train\"\n",
    "bus_types_stops[\"type_vehicle\"] = \"Bus\"\n",
    "tram_types_stops[\"type_vehicle\"] = \"Tram\"\n",
    "\n",
    "names = pd.concat([train_types, bus_types, tram_types])\n",
    "names_hour = pd.concat([train_types_hour, bus_types_hour, tram_types_hour])\n",
    "names_stops_hour = pd.concat([train_types_stops, bus_types_stops, tram_types_stops])\n",
    "\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "\n",
    "def mapping(x):\n",
    "    return route_id_to_route_name_dict[x]\n",
    "\n",
    "def get_vehicle_type(x):\n",
    "    if (x == \"Walking\"):\n",
    "        return x\n",
    "    y = x.split(\" \")[0]\n",
    "    if (y != \"Tram\" and y != \"Bus\"):\n",
    "        return \"Train\"\n",
    "    return y\n",
    "\n",
    "def get_vehicle_number(x):\n",
    "    if (x == \"Walking\"):\n",
    "        return x\n",
    "        \n",
    "    y = x.split(\" \")\n",
    "    if (len(y) == 2):\n",
    "        return y[1]\n",
    "    return y[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def minutes_to_hour(minutes):\n",
    "    if int(minutes) < 60:\n",
    "        return str(minutes)\n",
    "    return str(int(minutes) // 60)\n",
    "\n",
    "def change_names(x):\n",
    "    y = x.split(\" \")\n",
    "    if (len(y) >= 2):\n",
    "        line_name = y[0].replace(\"RegioExpress\", \"RE\").replace(\"Intercity\", \"IC\").replace(\"Extrazug\", \"EXT\").replace(\"InterRegio\", \"IR\").replace(\"S-Bahn\", \"S\")\n",
    "        line_number = y[1].replace(\"-Y\", \"\")\n",
    "        if (line_name ==\"Bus\" or line_name == \"Tram\" ):\n",
    "            return line_number\n",
    "        \n",
    "        return line_name + line_number\n",
    "    else:\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exponential_cdf(x):\n",
    "    return 1 - np.exp(x)\n",
    "\n",
    "def compute_prob(segments, end_time):\n",
    "    prob = 1.0\n",
    "    df = pd.DataFrame(segments, columns = [\"seg_number\", \"start_stop\", \"end_stop\", \"route_id\", \"departure_time\", \"duration\", \"stops\"])\n",
    "    \n",
    "    for index in range(len(df)-1):\n",
    "        if (df.iloc[index+1][\"route_id\"] == \"Walking\"):\n",
    "            df.at[index,\"duration\"] = df.iloc[index][\"duration\"] + df.iloc[index+1][\"duration\"]\n",
    "            \n",
    "    df= df[df.route_id != \"Walking\"]\n",
    "    \n",
    "    df[\"hour\"] = df[\"departure_time\"] + df[\"duration\"]\n",
    "    df[\"hour\"] = df[\"hour\"].apply(lambda x :minutes_to_hour(x) )\n",
    "    df[\"type\"] = df[\"route_id\"].apply(mapping)\n",
    "    df[\"type_vehicle\"] = df[\"type\"].apply(get_vehicle_type)\n",
    "    df[\"transport_name\"] = df[\"type\"].apply(change_names)\n",
    "    df.drop(columns=[\"type\"], inplace=True)\n",
    "    names_stops_hour_df = names_stops_hour.rename(columns= {\"stop_id\": \"end_stop\", \"line_name\": \"transport_name\"})\n",
    "    df[\"hour\"] = df[\"hour\"].astype(int)\n",
    "    \n",
    "    \n",
    "    \n",
    "    df[\"next_departure\"] = 0\n",
    "    df[\"next_departure\"][0:-1] = df[\"departure_time\"][1:]\n",
    "    df[\"next_departure\"].iloc[-1]= end_time\n",
    "    df[\"max_delay\"]= df[\"next_departure\"]- (df[\"departure_time\"]+ df[\"duration\"])\n",
    "    \n",
    "    \n",
    "    df= df.merge(names_stops_hour_df, on= [\"end_stop\", \"type_vehicle\", \"transport_name\", \"hour\"] , how= \"left\")\n",
    "    df.at[2, \"avg_delay\"]= np.nan\n",
    "\n",
    "    non_nulls= df[~df.avg_delay.isna()]\n",
    "    if (not non_nulls.empty):\n",
    "        non_nulls[\"param\"]= -((non_nulls[\"max_delay\"]*60)/non_nulls[\"avg_delay\"])\n",
    "        non_nulls[\"prob\"]= non_nulls[\"param\"].apply(exponential_cdf)\n",
    "        prob *= non_nulls[\"prob\"].agg('prod')\n",
    "    \n",
    "    nulls= df[df.avg_delay.isna()]\n",
    "    \n",
    "    if (not nulls.empty):\n",
    "        names_hour_df= names_hour.rename(columns= {\"line_name\": \"transport_name\"})\n",
    "        nulls.drop(columns=[\"avg_delay\"], inplace= True)\n",
    "        nulls = nulls.merge(names_hour_df, on= [\"type_vehicle\", \"transport_name\", \"hour\"], how= \"left\" )\n",
    "        non_nulls= nulls[~ nulls.avg_delay.isna()]\n",
    "        if (not non_nulls.empty):\n",
    "            non_nulls[\"param\"]= -((non_nulls[\"max_delay\"]*60)/non_nulls[\"avg_delay\"])\n",
    "            non_nulls[\"prob\"]= non_nulls[\"param\"].apply(exponential_cdf)\n",
    "            prob *= non_nulls[\"prob\"].agg('prod')\n",
    "        \n",
    "        nulls= nulls[nulls.avg_delay.isna()]\n",
    "        if (not nulls.empty):\n",
    "            names_df = names.rename(columns={\"line_name\": \"transport_name\"})\n",
    "            nulls.drop(columns=[\"avg_delay\"], inplace=True)\n",
    "            nulls = nulls.merge(names_df, on=[\"type_vehicle\", \"transport_name\"], how=\"left\" )\n",
    "            non_nulls = nulls[~nulls.avg_delay.isna()]\n",
    "            if (not non_nulls.empty):\n",
    "                non_nulls[\"param\"] = -((non_nulls[\"max_delay\"]*60)/non_nulls[\"avg_delay\"])\n",
    "                non_nulls[\"prob\"] = non_nulls[\"param\"].apply(exponential_cdf)\n",
    "                prob *= non_nulls[\"prob\"].agg('prod')\n",
    "\n",
    "    return prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate N paths "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_n_journeys(dep, dest, day, arrival_time, q, n=5):\n",
    "    day_edges = transport_edges[transport_edges.weekday == day]\n",
    "    all_roads = latest_departure_paths(day_edges, dest , arrival_time, walking_edges)\n",
    "    generator = generate_best_paths(all_roads, walking_edges, dep, dest, arrival_time)\n",
    "    \n",
    "    journey_list = {}\n",
    "    i = 1\n",
    "    while len(journey_list) < n:\n",
    "        try:\n",
    "            journey = next(generator)\n",
    "        except StopIteration:\n",
    "            return journey_list\n",
    "        \n",
    "        print('here')\n",
    "        \n",
    "        segments = journey_to_segments(journey, dep)\n",
    "        journey_q = compute_prob(segments, arrival_time)\n",
    "        \n",
    "        if journey_q >= q:\n",
    "            journey_list[i] = [seg + (journey_q,) for seg in segments]\n",
    "            i += 1\n",
    "        \n",
    "    return journey_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pretty print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_to_minutes(timestamp):\n",
    "        return int(timestamp[:2]) * 60 + int(timestamp[3:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def minutes_to_timestamp(minutes):\n",
    "    if minutes < 60:\n",
    "        return str(minutes)\n",
    "    return str(minutes // 60) + ':' + str(minutes % 60).zfill(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def minutes_to_duration(minutes):\n",
    "    if minutes < 60:\n",
    "        return str(minutes) + ' min'\n",
    "    return str(minutes // 60) + ' hr ' + str(minutes % 60) + ' min'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pretty_print_journey(journey):\n",
    "    journey_str = '\\n'.join([\"%s : %s\\n|\\n| %s (%s min)\\n| %s\\n|\\n%s : %s\\n\" % (minutes_to_timestamp(time), \n",
    "                                                                             stop_id_to_stop_dict[start],\n",
    "                                                                             route_id_to_route_name_dict[route_id],\n",
    "                                                                             minutes_to_timestamp(duration),\n",
    "                                                                             ' -> '.join([stop_id_to_stop_dict[s] for s in stops]) if route_id != 'Walking' else '',\n",
    "                                                                             minutes_to_timestamp(time + duration),\n",
    "                                                                             stop_id_to_stop_dict[end]) for _, start, end, route_id, time, duration, stops in journey])\n",
    "    return journey_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def journeys_to_str(journey_list):\n",
    "    if len(journey_list) == 0:\n",
    "        return \"No possible path\"\n",
    "\n",
    "    res = []\n",
    "    for i in journey_list.keys():\n",
    "        segment_list = sorted(journey_list[i], key = lambda e: e[0])\n",
    "        res.append(pretty_print_journey(segment_list))\n",
    "    return '\\n******************************\\n'.join(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "from ipywidgets import interact\n",
    "\n",
    "def map_plot():\n",
    "    fig = go.Figure()\n",
    "\n",
    "    fig.add_trace(go.Scattermapbox(\n",
    "    ))\n",
    "\n",
    "    fig.update_layout(\n",
    "        hovermode='closest',\n",
    "        mapbox=dict(\n",
    "            style='carto-positron',\n",
    "            bearing=0,\n",
    "            pitch=0,\n",
    "            zoom=11\n",
    "        ),\n",
    "        height=900,\n",
    "        width=1200\n",
    "    )\n",
    "\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = map_plot()\n",
    "stream_fig = go.FigureWidget(fig)\n",
    "stream_data = stream_fig.data\n",
    "\n",
    "def show_path(journey_segments):\n",
    "    if len(journey_segments) == 0:\n",
    "        return\n",
    "\n",
    "    journey = sorted(journey_segments, key = lambda e: e[0])        \n",
    "    \n",
    "    departure_time = journey[0][4]\n",
    "    arrival_time = journey[-1][4] + journey[-1][5]\n",
    "    \n",
    "    q = journey[0][-1]\n",
    "    \n",
    "    stops_per_segment = [seg[-1] for seg in journey]\n",
    "    \n",
    "    stops_per_segment_no_duplicates = [stops_per_segment[0]] + [ss[1:] for ss in stops_per_segment[1:]]\n",
    "\n",
    "    stops = [item for sublist in stops_per_segment_no_duplicates for item in sublist]\n",
    "    \n",
    "    lats = [stop_id_to_lat_dict[s] for s in stops]\n",
    "    lons = [stop_id_to_lon_dict[s] for s in stops]\n",
    "    \n",
    "    departure_stop = stops[0]\n",
    "    arrival_stop = stops[-1]\n",
    "    \n",
    "    # Reset figure and center figure\n",
    "    with stream_fig.batch_update():\n",
    "        stream_fig.data = stream_fig.data[:1]\n",
    "        stream_fig.update_layout(mapbox_center=dict(lat = (max(lats)+min(lats))/2, lon = (max(lons)+min(lons))/2))\n",
    "        stream_fig.update_layout(mapbox_zoom=11)\n",
    "        stream_fig.update_layout(legend_traceorder=\"reversed\", legend_valign='top')\n",
    "        stream_fig.update_layout(title_text='%s (%s) -> %s (%s) - %s' % (stop_id_to_stop_dict[departure_stop],\n",
    "                                                                         minutes_to_timestamp(departure_time),\n",
    "                                                                         stop_id_to_stop_dict[arrival_stop],\n",
    "                                                                         minutes_to_timestamp(arrival_time),\n",
    "                                                                         'CL = {:.2%}'.format(q)))\n",
    "    \n",
    "    \n",
    "    stops_per_route = [(seg[3], seg[4], seg[5], seg[-2]) for seg in journey]\n",
    "    \n",
    "    for route_id, time, duration, stops in reversed(stops_per_route):\n",
    "        stop_names = [stop_id_to_stop_dict[s] for s in stops]\n",
    "        \n",
    "        trace_name = '<b>' + route_id_to_route_name_dict[route_id] + '</b><br>%s %s<br>%s' % (stop_names[0],\n",
    "                                                                                              minutes_to_timestamp(time),\n",
    "                                                                                              minutes_to_duration(duration))\n",
    "        \n",
    "        if route_id != 'Walking':\n",
    "            trace_name += ' (%d stops)' % (len(stops)-1)\n",
    "        trace_name += '<br>%s %s' % (stop_names[-1], minutes_to_timestamp(time + duration))\n",
    "        \n",
    "        with stream_fig.batch_update():\n",
    "            stream_fig.add_trace(go.Scattermapbox(\n",
    "                lat=[stop_id_to_lat_dict[s] for s in stops],\n",
    "                lon=[stop_id_to_lon_dict[s] for s in stops],\n",
    "                mode='lines+markers',\n",
    "                marker=go.scattermapbox.Marker(\n",
    "                    size=6,\n",
    "                ),\n",
    "                opacity=1,\n",
    "                hovertext=stop_names,\n",
    "                name=trace_name,\n",
    "                hoverinfo=\"text+name\",\n",
    "                hoverlabel_namelength=-1,\n",
    "                showlegend=True\n",
    "            ))\n",
    "            \n",
    "    return stream_fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_name_to_id = sorted(list({v:k for k,v in stop_id_to_stop_dict.items()}.items()))\n",
    "weekdays = [(s, s.lower()) for s in ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday']]\n",
    "times = [(minutes_to_timestamp(m), m) for m in range(8*60, 20*60+1, 10)]\n",
    "percentages = list(reversed([(\"{:.0%}\".format(p/20), p) for p in range(21)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipywidgets import interact_manual, Dropdown, HBox, Label, interact\n",
    "from IPython.display import display\n",
    "\n",
    "style = {'description_width': '100px'}\n",
    "\n",
    "dep_widget = Dropdown(options=stop_name_to_id, value=None, description= 'Departure stop:', style=style)\n",
    "dest_widget = Dropdown(options=stop_name_to_id, value=None, description='Destination stop:', style=style)\n",
    "day_widget = Dropdown(options=weekdays, value=None, description='Day:', style=style)\n",
    "arr_time_widget = Dropdown(options=times, value=None, description='Arrival time:', style=style)\n",
    "Q_widget = Dropdown(options=percentages, value=None, description='Confidence level:', style=style)\n",
    "\n",
    "\n",
    "def ask_for_input(dep, dest, day, arr_time, Q):\n",
    "    if (dep and dest and day and arr_time and Q) is None:\n",
    "        print(\"Please set all the parameters.\")\n",
    "        return\n",
    "    \n",
    "    journeys = generate_n_journeys(dep, dest, day, arr_time, Q)\n",
    "    \n",
    "    if len(journeys) == 0:\n",
    "        print('Sorry, no journeys were found for the desired parameters.')\n",
    "        return\n",
    "    \n",
    "    @interact(i=Dropdown(options=journeys.keys(), description='Journey number:', style=style))\n",
    "    def show_fig(i):\n",
    "        return show_path(journeys[i])\n",
    "    \n",
    "\n",
    "im = interact_manual(ask_for_input, dep=dep_widget, dest=dest_widget, day=day_widget, arr_time=arr_time_widget, Q=Q_widget)\n",
    "im.widget.children[5].description = 'Search'\n",
    "\n",
    "\n",
    "@interact\n",
    "def f():\n",
    "    im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
