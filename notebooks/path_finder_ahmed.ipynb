{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Path Finder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup Spark environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Current session configs: <tt>{'name': 'jellouli-final-path-finder', 'executorMemory': '4G', 'executorCores': 4, 'numExecutors': 10, 'driverMemory': '4G', 'kind': 'pyspark'}</tt><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tr><th>ID</th><th>YARN Application ID</th><th>Kind</th><th>State</th><th>Spark UI</th><th>Driver log</th><th>User</th><th>Current session?</th></tr><tr><td>5924</td><td>application_1618324153128_5321</td><td>pyspark</td><td>busy</td><td><a target=\"_blank\" href=\"http://iccluster040.iccluster.epfl.ch:8088/proxy/application_1618324153128_5321/\">Link</a></td><td><a target=\"_blank\" href=\"http://iccluster078.iccluster.epfl.ch:8042/node/containerlogs/container_e01_1618324153128_5321_01_000001/ebouille\">Link</a></td><td>None</td><td></td></tr><tr><td>5978</td><td>application_1618324153128_5403</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://iccluster040.iccluster.epfl.ch:8088/proxy/application_1618324153128_5403/\">Link</a></td><td><a target=\"_blank\" href=\"http://iccluster066.iccluster.epfl.ch:8042/node/containerlogs/container_e01_1618324153128_5403_01_000001/ebouille\">Link</a></td><td>None</td><td></td></tr><tr><td>5983</td><td>application_1618324153128_5409</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://iccluster040.iccluster.epfl.ch:8088/proxy/application_1618324153128_5409/\">Link</a></td><td><a target=\"_blank\" href=\"http://iccluster067.iccluster.epfl.ch:8042/node/containerlogs/container_e01_1618324153128_5409_01_000001/ebouille\">Link</a></td><td>None</td><td></td></tr><tr><td>5986</td><td>application_1618324153128_5413</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://iccluster040.iccluster.epfl.ch:8088/proxy/application_1618324153128_5413/\">Link</a></td><td><a target=\"_blank\" href=\"http://iccluster066.iccluster.epfl.ch:8042/node/containerlogs/container_e01_1618324153128_5413_01_000001/ebouille\">Link</a></td><td>None</td><td></td></tr><tr><td>5992</td><td>application_1618324153128_5421</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://iccluster040.iccluster.epfl.ch:8088/proxy/application_1618324153128_5421/\">Link</a></td><td><a target=\"_blank\" href=\"http://iccluster071.iccluster.epfl.ch:8042/node/containerlogs/container_e01_1618324153128_5421_01_000001/ebouille\">Link</a></td><td>None</td><td></td></tr><tr><td>5994</td><td>application_1618324153128_5423</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://iccluster040.iccluster.epfl.ch:8088/proxy/application_1618324153128_5423/\">Link</a></td><td><a target=\"_blank\" href=\"http://iccluster070.iccluster.epfl.ch:8042/node/containerlogs/container_e01_1618324153128_5423_01_000001/ebouille\">Link</a></td><td>None</td><td></td></tr><tr><td>6004</td><td>application_1618324153128_5437</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://iccluster040.iccluster.epfl.ch:8088/proxy/application_1618324153128_5437/\">Link</a></td><td><a target=\"_blank\" href=\"http://iccluster067.iccluster.epfl.ch:8042/node/containerlogs/container_e01_1618324153128_5437_01_000001/ebouille\">Link</a></td><td>None</td><td></td></tr><tr><td>6005</td><td>application_1618324153128_5438</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://iccluster040.iccluster.epfl.ch:8088/proxy/application_1618324153128_5438/\">Link</a></td><td><a target=\"_blank\" href=\"http://iccluster069.iccluster.epfl.ch:8042/node/containerlogs/container_e01_1618324153128_5438_01_000001/ebouille\">Link</a></td><td>None</td><td></td></tr><tr><td>6008</td><td>application_1618324153128_5441</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://iccluster040.iccluster.epfl.ch:8088/proxy/application_1618324153128_5441/\">Link</a></td><td><a target=\"_blank\" href=\"http://iccluster077.iccluster.epfl.ch:8042/node/containerlogs/container_e01_1618324153128_5441_01_000001/ebouille\">Link</a></td><td>None</td><td></td></tr><tr><td>6009</td><td>application_1618324153128_5442</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://iccluster040.iccluster.epfl.ch:8088/proxy/application_1618324153128_5442/\">Link</a></td><td><a target=\"_blank\" href=\"http://iccluster069.iccluster.epfl.ch:8042/node/containerlogs/container_e01_1618324153128_5442_01_000002/ebouille\">Link</a></td><td>None</td><td></td></tr><tr><td>6012</td><td>application_1618324153128_5445</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://iccluster040.iccluster.epfl.ch:8088/proxy/application_1618324153128_5445/\">Link</a></td><td><a target=\"_blank\" href=\"http://iccluster070.iccluster.epfl.ch:8042/node/containerlogs/container_e01_1618324153128_5445_01_000001/ebouille\">Link</a></td><td>None</td><td></td></tr><tr><td>6013</td><td>application_1618324153128_5446</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://iccluster040.iccluster.epfl.ch:8088/proxy/application_1618324153128_5446/\">Link</a></td><td><a target=\"_blank\" href=\"http://iccluster070.iccluster.epfl.ch:8042/node/containerlogs/container_e01_1618324153128_5446_01_000001/ebouille\">Link</a></td><td>None</td><td></td></tr><tr><td>6014</td><td>application_1618324153128_5447</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://iccluster040.iccluster.epfl.ch:8088/proxy/application_1618324153128_5447/\">Link</a></td><td><a target=\"_blank\" href=\"http://iccluster066.iccluster.epfl.ch:8042/node/containerlogs/container_e01_1618324153128_5447_01_000001/ebouille\">Link</a></td><td>None</td><td></td></tr><tr><td>6018</td><td>application_1618324153128_5452</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://iccluster040.iccluster.epfl.ch:8088/proxy/application_1618324153128_5452/\">Link</a></td><td><a target=\"_blank\" href=\"http://iccluster068.iccluster.epfl.ch:8042/node/containerlogs/container_e01_1618324153128_5452_01_000001/ebouille\">Link</a></td><td>None</td><td></td></tr><tr><td>6021</td><td>application_1618324153128_5456</td><td>pyspark</td><td>busy</td><td><a target=\"_blank\" href=\"http://iccluster040.iccluster.epfl.ch:8088/proxy/application_1618324153128_5456/\">Link</a></td><td><a target=\"_blank\" href=\"http://iccluster069.iccluster.epfl.ch:8042/node/containerlogs/container_e01_1618324153128_5456_01_000001/ebouille\">Link</a></td><td>None</td><td></td></tr><tr><td>6023</td><td>application_1618324153128_5458</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://iccluster040.iccluster.epfl.ch:8088/proxy/application_1618324153128_5458/\">Link</a></td><td><a target=\"_blank\" href=\"http://iccluster077.iccluster.epfl.ch:8042/node/containerlogs/container_e01_1618324153128_5458_01_000001/ebouille\">Link</a></td><td>None</td><td></td></tr><tr><td>6025</td><td>application_1618324153128_5460</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://iccluster040.iccluster.epfl.ch:8088/proxy/application_1618324153128_5460/\">Link</a></td><td><a target=\"_blank\" href=\"http://iccluster078.iccluster.epfl.ch:8042/node/containerlogs/container_e01_1618324153128_5460_01_000001/ebouille\">Link</a></td><td>None</td><td></td></tr><tr><td>6026</td><td>application_1618324153128_5461</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://iccluster040.iccluster.epfl.ch:8088/proxy/application_1618324153128_5461/\">Link</a></td><td><a target=\"_blank\" href=\"http://iccluster078.iccluster.epfl.ch:8042/node/containerlogs/container_e01_1618324153128_5461_01_000001/ebouille\">Link</a></td><td>None</td><td></td></tr><tr><td>6031</td><td>application_1618324153128_5466</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://iccluster040.iccluster.epfl.ch:8088/proxy/application_1618324153128_5466/\">Link</a></td><td><a target=\"_blank\" href=\"http://iccluster072.iccluster.epfl.ch:8042/node/containerlogs/container_e01_1618324153128_5466_01_000002/ebouille\">Link</a></td><td>None</td><td></td></tr><tr><td>6032</td><td>application_1618324153128_5467</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://iccluster040.iccluster.epfl.ch:8088/proxy/application_1618324153128_5467/\">Link</a></td><td><a target=\"_blank\" href=\"http://iccluster066.iccluster.epfl.ch:8042/node/containerlogs/container_e01_1618324153128_5467_01_000001/ebouille\">Link</a></td><td>None</td><td></td></tr><tr><td>6037</td><td>application_1618324153128_5472</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://iccluster040.iccluster.epfl.ch:8088/proxy/application_1618324153128_5472/\">Link</a></td><td><a target=\"_blank\" href=\"http://iccluster068.iccluster.epfl.ch:8042/node/containerlogs/container_e01_1618324153128_5472_01_000001/ebouille\">Link</a></td><td>None</td><td></td></tr><tr><td>6038</td><td>application_1618324153128_5475</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://iccluster040.iccluster.epfl.ch:8088/proxy/application_1618324153128_5475/\">Link</a></td><td><a target=\"_blank\" href=\"http://iccluster071.iccluster.epfl.ch:8042/node/containerlogs/container_e01_1618324153128_5475_01_000002/ebouille\">Link</a></td><td>None</td><td></td></tr><tr><td>6041</td><td>application_1618324153128_5478</td><td>pyspark</td><td>starting</td><td><a target=\"_blank\" href=\"http://iccluster040.iccluster.epfl.ch:8088/proxy/application_1618324153128_5478/\">Link</a></td><td></td><td>None</td><td></td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%local\n",
    "import os\n",
    "username = os.environ['JUPYTERHUB_USER']\n",
    "get_ipython().run_cell_magic('configure', line=\"-f\", cell='{ \"name\":\"%s-final-path-finder\", \"executorMemory\":\"4G\", \"executorCores\":4, \"numExecutors\":10, \"driverMemory\": \"4G\" }' % username)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Spark application\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The code failed because of a fatal error:\n",
      "\tSession 6042 did not start up in 60 seconds..\n",
      "\n",
      "Some things to try:\n",
      "a) Make sure Spark has enough available resources for Jupyter to create a Spark context.\n",
      "b) Contact your Jupyter administrator to make sure the Spark magics library is configured correctly.\n",
      "c) Restart the kernel.\n"
     ]
    }
   ],
   "source": [
    "%%send_to_spark -i username -t str -n username"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The code failed because of a fatal error:\n",
      "\tSession 6042 did not start up in 60 seconds..\n",
      "\n",
      "Some things to try:\n",
      "a) Make sure Spark has enough available resources for Jupyter to create a Spark context.\n",
      "b) Contact your Jupyter administrator to make sure the Spark magics library is configured correctly.\n",
      "c) Restart the kernel.\n"
     ]
    }
   ],
   "source": [
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql.types import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import data from HDFS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "routes = spark.read.csv('/data/sbb/csv/timetable/routes/2019/05/07/routes.csv', header=True )\n",
    "stops = spark.read.orc('/data/sbb/orc/geostops')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "walking_edges = spark.read.parquet('/user/%s/final/parquet/walking_edges' % username)\n",
    "transport_edges = spark.read.parquet('/user/%s/final/parquet/transport_edges' % username)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['start_vertex', 'end_vertex', 'start_time', 'duration', 'route_id', 'weekday']"
     ]
    }
   ],
   "source": [
    "transport_edges.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shortest Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "walking_edges = walking_edges.withColumn('value', F.struct(F.col('end_vertex'), F.col('duration')))\\\n",
    "                             .groupBy('start_vertex').agg({'value': 'collect_set'})\\\n",
    "                             .toPandas()\\\n",
    "                             .set_index('start_vertex')\\\n",
    "                             .to_dict()['collect_set(value)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "edges = transport_edges.filter('weekday == \"monday\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# This function assumes a (spark) dataframe with columns 'start_vertex', 'end_vertex', 'start_time', 'duration', 'route_id' \n",
    "# edges is a dataframe that represents the edges of the graph, \n",
    "# edges should be sorted by order of descending starting time\n",
    "# inward_walking_edges is a map route_id -> list(route_id), representing the nodes from which we can walk to a given node\n",
    "# walking_edge_duration is a map (route_id, route_id) -> float, representing the duration of the walk\n",
    "# end_time should be in the format 'HH:MM'\n",
    "def latest_departure_paths(edges, end_stop, end_time, walking_edges):\n",
    "\n",
    "    def edge_valid(u, v, time, dur, route_id): \n",
    "        next_edges = all_roads.get(v, [])\n",
    "        \n",
    "        # Can we reach the destination ?\n",
    "        if v == end_stop and time + dur <= end_time: \n",
    "             return (time, v, route_id, dur)\n",
    "        \n",
    "        # We don't add edges starting at the destination\n",
    "        if u != end_stop:\n",
    "            for edge in next_edges[::-1]: # Traverse the list in reverse order because it's sorted by descending starting time\n",
    "                time_v, next_v, route_id_v, dur_v = edge\n",
    "                if (route_id == route_id_v and time + dur <= time_v) or (time + dur + transfer_time <= time_v): \n",
    "                    return (time, v, route_id, dur)            \n",
    "            \n",
    "            # Can we walk from v instead?\n",
    "            for end_vertex, walking_duration in walking_edges.get(v, []):\n",
    "                if end_vertex != u: # do not loop back to u\n",
    "                    for next_next_edge in all_roads.get(end_vertex, []):\n",
    "                        time_next = next_next_edge[0]\n",
    "                        if time + dur <= time_next - walking_duration - transfer_time : # can we make in time to v in order to walk\n",
    "                            return (time, v, route_id, dur)\n",
    "                \n",
    "        return None\n",
    "                \n",
    "    def time_to_minutes(timestamp):\n",
    "        return int(timestamp[:2]) * 60 + int(timestamp[3:5])\n",
    "    \n",
    "    \n",
    "    transfer_time = 2 # at least 2 minutes to transfer\n",
    "    max_walking_time = 10\n",
    "    \n",
    "    all_roads = {}\n",
    "    end_time = time_to_minutes(end_time)\n",
    "    start_time = end_time - 120 # look only at edges departing at most 2 hours before end_time\n",
    "        \n",
    "    edges = edges.filter(F.col('start_time').between(start_time, end_time)).toPandas().sort_values(by=['start_time'], ascending=False).to_numpy()\n",
    "\n",
    "    for row in edges:\n",
    "        start_vertex, end_vertex, start, duration, route_id = row[:5]\n",
    "        \n",
    "        update = edge_valid(start_vertex, end_vertex, start, duration, route_id)\n",
    "        if update:\n",
    "            if start_vertex in all_roads:    \n",
    "                all_roads[start_vertex].append(update)\n",
    "            else:\n",
    "                all_roads[start_vertex] = [update]\n",
    "                        \n",
    "    return all_roads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.60806584358"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "all_roads = latest_departure_paths(edges, '8591221', '20:00', walking_edges)\n",
    "end = time.time() \n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "stop_id_to_stop = stops.select('stop_id', 'stop_name')\n",
    "stop_id_to_stop_dict = stop_id_to_stop.toPandas().set_index('stop_id').to_dict()['stop_name']\n",
    "\n",
    "route_id_to_route_name = routes.withColumn('route_name', F.concat(F.col('route_desc'), F.lit(' '), F.col('route_short_name')))\\\n",
    "                               .select('route_id', 'route_desc', 'route_short_name', 'route_name')\n",
    "route_id_to_route_name_dict = route_id_to_route_name.toPandas().set_index('route_id').to_dict()['route_name']\n",
    "route_id_to_route_name_dict['Walking'] = 'Walk'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Journey reconstruction\n",
    "\n",
    "from itertools import groupby\n",
    "import numpy as np\n",
    "\n",
    "def minutes_to_timestamp(minutes):\n",
    "    return str(minutes // 60) + ':' + str(minutes % 60).zfill(2)\n",
    "\n",
    "def select_next(edge, all_roads, walking_edges, transfer_time=2):\n",
    "    \n",
    "    next_edges = all_roads.get(node, [])\n",
    "\n",
    "    if edge[2] == 'Walking':\n",
    "        return [next_edges[-1]]\n",
    "    else:\n",
    "        \n",
    "        prev_time, node,  prev_route_id, prev_duration = edge    \n",
    "        next_edges += get_walking_edges(all_roads, node, walking_edges)\n",
    "        possible_edges = []\n",
    "        for edge in next_edges:\n",
    "            t, v, route_id, dur = edge\n",
    "            if prev_route_id != route_id and prev_time + prev_duration + transfer_time <= t:\n",
    "                possible_edges.append(edge)\n",
    "            elif prev_route_id == route_id and prev_time + prev_duration <= t:\n",
    "                possible_edges.append(edge)\n",
    "\n",
    "        return possible_edges\n",
    "    \n",
    "def iterate_all_edges(start_edges, end_stop, all_roads, walking_edges, cur_list):\n",
    "    for edge in start_edges:\n",
    "        t, v, route_id, dur = edge\n",
    "        if v == end_stop: # have we reached the destination?\n",
    "            yield cur_list + [edge]\n",
    "        else:\n",
    "            next_edges = select_next(edge,  all_roads, walking_edges)\n",
    "            for journey in iterate_all_edges(next_edges, end_stop, all_roads, walking_edges, cur_list + [edge]):\n",
    "                yield journey\n",
    "\n",
    "def get_journey_attributes(journey):\n",
    "    walking_distance = sum([t[-1] for t in journey if t[-1] == 'Walking'])\n",
    "    transfers = len(set([t[2] for t in journey if t[2] != 'Walking']))\n",
    "    return [transfers, walking_distance]\n",
    "    \n",
    "def get_walking_edges(all_roads, node, walking_edges, transfer_time=2):\n",
    "    # Compute viable walks starting at node u:\n",
    "    possible_walking_edges = []\n",
    "    for end_vertex, duration in walking_edges.get(node, []):\n",
    "        for index, edge in enumerate(all_roads.get(end_vertex, [])):\n",
    "            time_next, node_next = edge[:2]\n",
    "            if node_next != node:\n",
    "                possible_walking_edges.append((time_next - duration - transfer_time, end_vertex, 'Walking', duration, index))\n",
    "    return possible_walking_edges\n",
    "    \n",
    "def generate_best_paths(all_roads, start_stop, end_stop, walking_edges):\n",
    "    # add possible paths that start by walking\n",
    "    start_edges = all_roads.get(start_stop, []) + get_walking_edges(all_roads, start_stop, walking_edges)\n",
    "    if not start_edges: # not paths were found\n",
    "        yield []\n",
    "    else:\n",
    "        # sort edges and group by start_time\n",
    "        start_edges = sorted(start_edges, key=lambda x:x[0], reverse=True)\n",
    "        start_edges = groupby(start_edges, key=lambda x:x[0])\n",
    "        \n",
    "        for start_time , edges in start_edges:\n",
    "            # find all possible journeys that start at time start_time\n",
    "            all_journeys = list(iterate_all_edges(list(edges), end_stop, all_roads, walking_edges, []))\n",
    "            journey_attribs = np.array([get_journey_attributes(journey) for journey in all_journeys])\n",
    "            sorted_indices = np.lexsort(journey_attribs.T)\n",
    "            for i in sorted_indices:\n",
    "                yield all_journeys[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb10abc58b99494e994622e0b1de9d00",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "An error was encountered:\n",
      "Invalid status code '400' from http://iccluster040.iccluster.epfl.ch:8998/sessions/6015/statements/17 with error payload: \"requirement failed: Session isn't active.\"\n"
     ]
    }
   ],
   "source": [
    "for k,v in all_roads.iteritems():\n",
    "    all_roads[k] = get_walking_edges(all_roads, k, walking_edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "start_stop = all_roads.keys()[29]\n",
    "end_stop = '8591221'\n",
    "iterator = generate_best_paths(all_roads, start_stop, end_stop, walking_edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e4319da290004f1189b0e54e144ec526",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "SparkStatementCancellationFailedException",
     "evalue": "Interrupted by user but Livy failed to cancel the Spark statement. The Livy session might have become unusable.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/sparkmagic/livyclientlib/command.py\u001b[0m in \u001b[0;36mexecute\u001b[0;34m(self, session)\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mstatement_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34mu'id'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_statement_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatement_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/sparkmagic/livyclientlib/command.py\u001b[0m in \u001b[0;36m_get_statement_output\u001b[0;34m(self, session, statement_id)\u001b[0m\n\u001b[1;32m     90\u001b[0m                 \u001b[0mprogress\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstatement\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'progress'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 91\u001b[0;31m                 \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mretries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m                 \u001b[0mretries\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/sparkmagic/livyclientlib/livysession.py\u001b[0m in \u001b[0;36msleep\u001b[0;34m(self, retries)\u001b[0m\n\u001b[1;32m    288\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 289\u001b[0;31m         \u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_policy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseconds_to_sleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mretries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    290\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mLivyClientTimeoutException\u001b[0m                Traceback (most recent call last)",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/sparkmagic/livyclientlib/command.py\u001b[0m in \u001b[0;36mexecute\u001b[0;34m(self, session)\u001b[0m\n\u001b[1;32m     54\u001b[0m                     \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhttp_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcancel_statement\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatement_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m                     \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait_for_idle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m             \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/sparkmagic/livyclientlib/livysession.py\u001b[0m in \u001b[0;36mwait_for_idle\u001b[0;34m(self, seconds_to_wait)\u001b[0m\n\u001b[1;32m    270\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 271\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mLivyClientTimeoutException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    272\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mLivyClientTimeoutException\u001b[0m: Session 6010 did not reach idle status in time. Current status is busy.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mSparkStatementCancellationFailedException\u001b[0m Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-cf6c87bb58b3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_cell_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'spark'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'journey = next(iterator)\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_cell_magic\u001b[0;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[1;32m   2360\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2361\u001b[0m                 \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmagic_arg_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2362\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2363\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<decorator-gen-125>\u001b[0m in \u001b[0;36mspark\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/IPython/core/magic.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(f, *a, **k)\u001b[0m\n\u001b[1;32m    185\u001b[0m     \u001b[0;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 187\u001b[0;31m         \u001b[0mcall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    188\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/sparkmagic/livyclientlib/exceptions.py\u001b[0m in \u001b[0;36mwrapped\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    138\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 140\u001b[0;31m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    141\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mconf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall_errors_are_fatal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/sparkmagic/livyclientlib/exceptions.py\u001b[0m in \u001b[0;36mwrapped\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    105\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 107\u001b[0;31m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    108\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mexceptions_to_handle\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mconf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall_errors_are_fatal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/sparkmagic/kernels/kernelmagics.py\u001b[0m in \u001b[0;36mspark\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n\u001b[1;32m    264\u001b[0m             \u001b[0mcoerce\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_coerce_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoerce\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 266\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute_spark\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcell\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msamplemethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaxrows\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msamplefraction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcoerce\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    267\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    268\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/sparkmagic/magics/sparkmagicsbase.py\u001b[0m in \u001b[0;36mexecute_spark\u001b[0;34m(self, cell, output_var, samplemethod, maxrows, samplefraction, session_name, coerce)\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mexecute_spark\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_var\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msamplemethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxrows\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msamplefraction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msession_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcoerce\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m         \u001b[0;34m(\u001b[0m\u001b[0msuccess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmimetype\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspark_controller\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCommand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msession_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msuccess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mconf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshutdown_session_on_spark_statement_errors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/sparkmagic/livyclientlib/sparkcontroller.py\u001b[0m in \u001b[0;36mrun_command\u001b[0;34m(self, command, client_name)\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrun_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcommand\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclient_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0msession_to_use\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_session_by_name_or_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclient_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mcommand\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession_to_use\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrun_sqlquery\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msqlquery\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclient_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/sparkmagic/livyclientlib/command.py\u001b[0m in \u001b[0;36mexecute\u001b[0;34m(self, session)\u001b[0m\n\u001b[1;32m     55\u001b[0m                     \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait_for_idle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m             \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mSparkStatementCancellationFailedException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCOMMAND_CANCELLATION_FAILED_MSG\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mSparkStatementCancelledException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCOMMAND_INTERRUPTED_MSG\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mSparkStatementCancellationFailedException\u001b[0m: Interrupted by user but Livy failed to cancel the Spark statement. The Livy session might have become unusable."
     ]
    }
   ],
   "source": [
    "journey = next(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def journey_to_segments (journey, start_stop):\n",
    "    segments = [(route_id, list(edges)) for (route_id, edges) in  groupby(journey, lambda x:x[2])]\n",
    "\n",
    "    segments = [(i + 1, edges[0][1], edges[-1][1], route_id, edges[0][0], edges[-1][0] + edges[-1][3] - edges[0][0], [t[1] for t in edges]) \\\n",
    "                for i, (route_id, edges) in enumerate(segments)]\n",
    "    \n",
    "    segments[0] = (segments[0][0], start_stop, segments[0][2], segments[0][3], segments[0][4], segments[0][5], [start_stop] + segments[0][6])\n",
    "    \n",
    "    return segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(1, '8530822', u'8591287', 'Walking', 1176, 8, ['8530822', u'8591287']), (2, u'8591239', u'8591221', u'26-31-j19-1', 1186, 10, [u'8591239', u'8591375', u'8530813', u'8591364', u'8530812', u'8591137', u'8591233', u'8591221'])]"
     ]
    }
   ],
   "source": [
    "journey_to_segments(journey, start_stop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def journey_to_df(journey_list):\n",
    "    arr = []\n",
    "    journey_number = 0\n",
    "    for journey in journey_list:\n",
    "        journey_number += 1\n",
    "        arr = arr + [(journey_number,) + seg for seg in journey]\n",
    "    \n",
    "    schema = StructType([\n",
    "        StructField(\"journey_number\", IntegerType(), True),\n",
    "        StructField(\"segment_number\", IntegerType(), True),\n",
    "        StructField(\"start_vertex\", StringType(), True),\n",
    "        StructField(\"end_vertex\", StringType(), True),\n",
    "        StructField(\"route_id\", StringType(), True),\n",
    "        StructField(\"departure_time\", StringType(), True),\n",
    "        StructField(\"duration\", StringType(), True),\n",
    "        StructField(\"stop_seq\", ArrayType(StringType()), True)\n",
    "    ])\n",
    "    \n",
    "    journey_df = spark.createDataFrame(arr, schema)\n",
    "    \n",
    "    return journey_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "journey_df = journey_to_df([journey_to_segments(journey, '8530822')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def pretty_print_journey(journey):\n",
    "    journey_str = '\\n'.join([\"%s : %s\\n|\\n| %s (%s min)\\n| %s\\n|\\n%s : %s\\n\" % (minutes_to_timestamp(time), \n",
    "                                                                             stop_id_to_stop_dict[start],\n",
    "                                                                             route_id_to_route_name_dict[route_id],\n",
    "                                                                             minutes_to_timestamp(duration),\n",
    "                                                                             ' -> '.join([stop_id_to_stop_dict[s] for s in stops]) if route_id != 'Walking' else '',\n",
    "                                                                             minutes_to_timestamp(time + duration),\n",
    "                                                                             stop_id_to_stop_dict[end]) for _, start, end, route_id, time, duration, stops in journey])\n",
    "    return journey_str"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Send to local"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Send transfer dataframe to local"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%spark -o next_transfer_df -n -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%local\n",
    "next_transfer_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reconstruct a dict for transfers to keep old code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%local\n",
    "next_transfer = {e[0]: tuple(e[1:]) for e in next_transfer_df.to_numpy()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Send route id to route name mapping to local"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%spark -o route_id_to_route_name -n -1\n",
    "route_id_to_route_name = routes.withColumn('route_name', F.concat(F.col('route_desc'), F.lit(' '), F.col('route_short_name')))\\\n",
    "                               .select('route_id', 'route_desc', 'route_short_name', 'route_name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%local\n",
    "route_id_to_route_name_dict = route_id_to_route_name.set_index('route_id').to_dict()['route_name']\n",
    "route_id_to_route_name_dict['walking'] = 'walk'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Send stop id to stop name mapping to local"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%spark -o stop_id_to_stop -n -1\n",
    "stop_id_to_stop = stops.select('stop_id', 'stop_name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%local\n",
    "stop_id_to_stop_dict = stop_id_to_stop.set_index('stop_id').to_dict()['stop_name']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reconstruct path and pretty print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%local\n",
    "def minutes_to_timestamp(minutes):\n",
    "    return str(minutes // 60) + ':' + str(minutes % 60).zfill(2)\n",
    "    \n",
    "    \n",
    "def reconstruct_journey(next_transfer, start_stop):\n",
    "    time, next_stop, route_id, duration, stop_seq = next_transfer[start_stop]\n",
    "    journey = []\n",
    "    while next_stop != start_stop:\n",
    "        journey.append(\n",
    "            (minutes_to_timestamp(time),\n",
    "             stop_id_to_stop_dict[start_stop], \n",
    "             route_id_to_route_name_dict[route_id],\n",
    "             duration,\n",
    "             'Ride %d stops' % (len(stop_seq)-1),\n",
    "             minutes_to_timestamp(time + duration),\n",
    "             stop_id_to_stop_dict[next_stop])\n",
    "        )\n",
    "        \n",
    "        start_stop = next_stop\n",
    "        time, next_stop, route_id, duration, stop_seq = next_transfer[next_stop]\n",
    "    return journey\n",
    "\n",
    "\n",
    "def pretty_print_journey(journey):\n",
    "    journey_str = '\\n'.join([\"%s : %s\\n|\\n| %s (%s min) %s\\n|\\n%s : %s\\n\" % segment for segment in journey])\n",
    "    return journey_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%local\n",
    "print(pretty_print_journey(reconstruct_journey(next_transfer, '8590883'))) # almost same as sbb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%local\n",
    "print(pretty_print_journey(reconstruct_journey(next_transfer, '8591353'))) # almost same as sbb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%local\n",
    "print(pretty_print_journey(reconstruct_journey(next_transfer, '8590788'))) # not in sbb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%local\n",
    "print(pretty_print_journey(reconstruct_journey(next_transfer, '8591368'))) # Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark",
   "language": "python",
   "name": "pysparkkernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "python",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "pyspark",
   "pygments_lexer": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
