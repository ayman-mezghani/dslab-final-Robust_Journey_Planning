{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Path Finder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup Spark environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Current session configs: <tt>{'name': 'hadidane-final-path-finder', 'executorMemory': '4G', 'executorCores': 4, 'numExecutors': 10, 'driverMemory': '4G', 'kind': 'pyspark'}</tt><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tr><th>ID</th><th>YARN Application ID</th><th>Kind</th><th>State</th><th>Spark UI</th><th>Driver log</th><th>User</th><th>Current session?</th></tr><tr><td>5316</td><td>application_1618324153128_4558</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://iccluster040.iccluster.epfl.ch:8088/proxy/application_1618324153128_4558/\">Link</a></td><td><a target=\"_blank\" href=\"http://iccluster066.iccluster.epfl.ch:8042/node/containerlogs/container_e01_1618324153128_4558_01_000001/ebouille\">Link</a></td><td>None</td><td></td></tr><tr><td>5336</td><td>application_1618324153128_4586</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://iccluster040.iccluster.epfl.ch:8088/proxy/application_1618324153128_4586/\">Link</a></td><td><a target=\"_blank\" href=\"http://iccluster078.iccluster.epfl.ch:8042/node/containerlogs/container_e01_1618324153128_4586_01_000001/ebouille\">Link</a></td><td>None</td><td></td></tr><tr><td>5342</td><td>application_1618324153128_4592</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://iccluster040.iccluster.epfl.ch:8088/proxy/application_1618324153128_4592/\">Link</a></td><td><a target=\"_blank\" href=\"http://iccluster078.iccluster.epfl.ch:8042/node/containerlogs/container_e01_1618324153128_4592_01_000001/ebouille\">Link</a></td><td>None</td><td></td></tr><tr><td>5349</td><td>application_1618324153128_4602</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://iccluster040.iccluster.epfl.ch:8088/proxy/application_1618324153128_4602/\">Link</a></td><td><a target=\"_blank\" href=\"http://iccluster067.iccluster.epfl.ch:8042/node/containerlogs/container_e01_1618324153128_4602_01_000001/ebouille\">Link</a></td><td>None</td><td></td></tr><tr><td>5368</td><td>application_1618324153128_4626</td><td>pyspark</td><td>busy</td><td><a target=\"_blank\" href=\"http://iccluster040.iccluster.epfl.ch:8088/proxy/application_1618324153128_4626/\">Link</a></td><td><a target=\"_blank\" href=\"http://iccluster069.iccluster.epfl.ch:8042/node/containerlogs/container_e01_1618324153128_4626_01_000001/ebouille\">Link</a></td><td>None</td><td></td></tr><tr><td>5376</td><td>application_1618324153128_4636</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://iccluster040.iccluster.epfl.ch:8088/proxy/application_1618324153128_4636/\">Link</a></td><td><a target=\"_blank\" href=\"http://iccluster077.iccluster.epfl.ch:8042/node/containerlogs/container_e01_1618324153128_4636_01_000001/ebouille\">Link</a></td><td>None</td><td></td></tr><tr><td>5377</td><td>application_1618324153128_4637</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://iccluster040.iccluster.epfl.ch:8088/proxy/application_1618324153128_4637/\">Link</a></td><td><a target=\"_blank\" href=\"http://iccluster071.iccluster.epfl.ch:8042/node/containerlogs/container_e01_1618324153128_4637_01_000002/ebouille\">Link</a></td><td>None</td><td></td></tr><tr><td>5391</td><td>application_1618324153128_4663</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://iccluster040.iccluster.epfl.ch:8088/proxy/application_1618324153128_4663/\">Link</a></td><td><a target=\"_blank\" href=\"http://iccluster078.iccluster.epfl.ch:8042/node/containerlogs/container_e01_1618324153128_4663_01_000001/ebouille\">Link</a></td><td>None</td><td></td></tr><tr><td>5392</td><td>application_1618324153128_4664</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://iccluster040.iccluster.epfl.ch:8088/proxy/application_1618324153128_4664/\">Link</a></td><td><a target=\"_blank\" href=\"http://iccluster072.iccluster.epfl.ch:8042/node/containerlogs/container_e01_1618324153128_4664_01_000001/ebouille\">Link</a></td><td>None</td><td></td></tr><tr><td>5394</td><td>application_1618324153128_4666</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://iccluster040.iccluster.epfl.ch:8088/proxy/application_1618324153128_4666/\">Link</a></td><td><a target=\"_blank\" href=\"http://iccluster078.iccluster.epfl.ch:8042/node/containerlogs/container_e01_1618324153128_4666_01_000001/ebouille\">Link</a></td><td>None</td><td></td></tr><tr><td>5395</td><td>application_1618324153128_4668</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://iccluster040.iccluster.epfl.ch:8088/proxy/application_1618324153128_4668/\">Link</a></td><td><a target=\"_blank\" href=\"http://iccluster067.iccluster.epfl.ch:8042/node/containerlogs/container_e01_1618324153128_4668_01_000001/ebouille\">Link</a></td><td>None</td><td></td></tr><tr><td>5397</td><td>application_1618324153128_4671</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://iccluster040.iccluster.epfl.ch:8088/proxy/application_1618324153128_4671/\">Link</a></td><td><a target=\"_blank\" href=\"http://iccluster067.iccluster.epfl.ch:8042/node/containerlogs/container_e01_1618324153128_4671_01_000001/ebouille\">Link</a></td><td>None</td><td></td></tr><tr><td>5398</td><td>application_1618324153128_4672</td><td>pyspark</td><td>busy</td><td><a target=\"_blank\" href=\"http://iccluster040.iccluster.epfl.ch:8088/proxy/application_1618324153128_4672/\">Link</a></td><td><a target=\"_blank\" href=\"http://iccluster066.iccluster.epfl.ch:8042/node/containerlogs/container_e01_1618324153128_4672_01_000001/ebouille\">Link</a></td><td>None</td><td></td></tr><tr><td>5399</td><td>application_1618324153128_4673</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://iccluster040.iccluster.epfl.ch:8088/proxy/application_1618324153128_4673/\">Link</a></td><td><a target=\"_blank\" href=\"http://iccluster068.iccluster.epfl.ch:8042/node/containerlogs/container_e01_1618324153128_4673_01_000001/ebouille\">Link</a></td><td>None</td><td></td></tr><tr><td>5407</td><td>application_1618324153128_4683</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://iccluster040.iccluster.epfl.ch:8088/proxy/application_1618324153128_4683/\">Link</a></td><td><a target=\"_blank\" href=\"http://iccluster077.iccluster.epfl.ch:8042/node/containerlogs/container_e01_1618324153128_4683_01_000001/ebouille\">Link</a></td><td>None</td><td></td></tr><tr><td>5409</td><td>application_1618324153128_4685</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://iccluster040.iccluster.epfl.ch:8088/proxy/application_1618324153128_4685/\">Link</a></td><td><a target=\"_blank\" href=\"http://iccluster078.iccluster.epfl.ch:8042/node/containerlogs/container_e01_1618324153128_4685_01_000001/ebouille\">Link</a></td><td>None</td><td></td></tr><tr><td>5412</td><td>application_1618324153128_4688</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://iccluster040.iccluster.epfl.ch:8088/proxy/application_1618324153128_4688/\">Link</a></td><td><a target=\"_blank\" href=\"http://iccluster068.iccluster.epfl.ch:8042/node/containerlogs/container_e01_1618324153128_4688_01_000001/ebouille\">Link</a></td><td>None</td><td></td></tr><tr><td>5413</td><td>application_1618324153128_4689</td><td>pyspark</td><td>busy</td><td><a target=\"_blank\" href=\"http://iccluster040.iccluster.epfl.ch:8088/proxy/application_1618324153128_4689/\">Link</a></td><td><a target=\"_blank\" href=\"http://iccluster071.iccluster.epfl.ch:8042/node/containerlogs/container_e01_1618324153128_4689_01_000001/ebouille\">Link</a></td><td>None</td><td></td></tr><tr><td>5414</td><td>application_1618324153128_4690</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://iccluster040.iccluster.epfl.ch:8088/proxy/application_1618324153128_4690/\">Link</a></td><td><a target=\"_blank\" href=\"http://iccluster067.iccluster.epfl.ch:8042/node/containerlogs/container_e01_1618324153128_4690_01_000002/ebouille\">Link</a></td><td>None</td><td></td></tr><tr><td>5415</td><td>application_1618324153128_4691</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://iccluster040.iccluster.epfl.ch:8088/proxy/application_1618324153128_4691/\">Link</a></td><td><a target=\"_blank\" href=\"http://iccluster069.iccluster.epfl.ch:8042/node/containerlogs/container_e01_1618324153128_4691_01_000002/ebouille\">Link</a></td><td>None</td><td></td></tr><tr><td>5416</td><td>application_1618324153128_4692</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://iccluster040.iccluster.epfl.ch:8088/proxy/application_1618324153128_4692/\">Link</a></td><td><a target=\"_blank\" href=\"http://iccluster078.iccluster.epfl.ch:8042/node/containerlogs/container_e01_1618324153128_4692_01_000001/ebouille\">Link</a></td><td>None</td><td></td></tr><tr><td>5418</td><td>application_1618324153128_4694</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://iccluster040.iccluster.epfl.ch:8088/proxy/application_1618324153128_4694/\">Link</a></td><td><a target=\"_blank\" href=\"http://iccluster071.iccluster.epfl.ch:8042/node/containerlogs/container_e01_1618324153128_4694_01_000001/ebouille\">Link</a></td><td>None</td><td></td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%local\n",
    "import os\n",
    "username = os.environ['JUPYTERHUB_USER']\n",
    "get_ipython().run_cell_magic('configure', line=\"-f\", cell='{ \"name\":\"%s-final-path-finder\", \"executorMemory\":\"4G\", \"executorCores\":4, \"numExecutors\":10, \"driverMemory\": \"4G\" }' % username)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Spark application\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tr><th>ID</th><th>YARN Application ID</th><th>Kind</th><th>State</th><th>Spark UI</th><th>Driver log</th><th>User</th><th>Current session?</th></tr><tr><td>5419</td><td>application_1618324153128_4695</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://iccluster040.iccluster.epfl.ch:8088/proxy/application_1618324153128_4695/\">Link</a></td><td><a target=\"_blank\" href=\"http://iccluster069.iccluster.epfl.ch:8042/node/containerlogs/container_e01_1618324153128_4695_01_000001/ebouille\">Link</a></td><td>None</td><td>✔</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SparkSession available as 'spark'.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully passed 'username' as 'username' to Spark kernel"
     ]
    }
   ],
   "source": [
    "%%send_to_spark -i username -t str -n username"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql.types import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import data from HDFS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "routes = spark.read.csv('/data/sbb/csv/timetable/routes/2019/05/07/routes.csv', header=True )\n",
    "stops = spark.read.orc('/data/sbb/orc/geostops')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "walking_edges = spark.read.parquet('/user/%s/final/parquet/walking_edges' % username)\n",
    "transport_edges = spark.read.parquet('/user/%s/final/parquet/transport_edges' % username)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['start_vertex', 'end_vertex', 'start_time', 'duration', 'route_id', 'weekday']"
     ]
    }
   ],
   "source": [
    "transport_edges.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shortest Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "inward_walking_edges = walking_edges.groupby('end_vertex').agg({'start_vertex': 'collect_set'})\\\n",
    "                                                              .withColumnRenamed('collect_set(start_vertex)', 'start_vertices')\\\n",
    "                                                              .toPandas().set_index('end_vertex').to_dict()['start_vertices']\n",
    "walking_edge_duration = walking_edges.toPandas()\n",
    "walking_edge_duration['key'] = walking_edge_duration.apply(lambda x: (x['start_vertex'], x['end_vertex']), axis=1)\n",
    "walking_edge_duration = walking_edge_duration.set_index('key').to_dict()['duration']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "edges = transport_edges.filter('weekday == \"monday\"').sort(F.col('start_time').desc())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# This function assumes a (spark) dataframe with columns 'start_vertex', 'end_vertex', 'start_time', 'duration', 'route_id' \n",
    "# edges is a dataframe that represents the edges of the graph, \n",
    "# edges should be sorted by order of descending starting time\n",
    "# inward_walking_edges is a map route_id -> list(route_id), representing the nodes from which we can walk to a given node\n",
    "# walking_edge_duration is a map (route_id, route_id) -> float, representing the duration of the walk\n",
    "# end_time should be in the format 'HH:MM'\n",
    "def latest_departure_paths(edges, end_stop, end_time, inward_walking_edges, walking_edge_duration):\n",
    "    \n",
    "    # This function computes whether edge (u, v, t, dur, route_id) can be taken\n",
    "    # returns update to node u if possible, and None otherwise\n",
    "    def edge_valid(u, v, time, dur, route_id):\n",
    "        \n",
    "        cur_best = next_transfer.get(u)\n",
    "        next_edge = next_transfer.get(v)\n",
    "        \n",
    "        if next_edge: # needs to be defined\n",
    "            time_v, next_v, route_id_v, dur_v, seq_v = next_edge\n",
    "            \n",
    "            if route_id == 'walking':\n",
    "                if  route_id_v == 'walking' and dur_v + dur <= max_walking_time:\n",
    "                    time = time_v - dur - transfer_time\n",
    "                    if (not cur_best) or time > cur_best[0]:\n",
    "                        return (time, next_v, route_id, dur + dur_v, [u] + seq_v)\n",
    "                elif route_id_v != 'walking':\n",
    "                    time = time_v - dur - transfer_time\n",
    "                    if (not cur_best) or time > cur_best[0]:\n",
    "                        return (time, v, route_id, dur, [u, v])\n",
    "                      \n",
    "            \n",
    "            elif (route_id == route_id_v or v == end_stop) and time + duration <= time_v: # same route or last_stop\n",
    "                if (not cur_best) or time > cur_best[0]: # can we improve\n",
    "                    return (time, next_v, route_id, dur + dur_v, [u] + seq_v)\n",
    "            \n",
    "            \n",
    "            elif time + duration + transfer_time <= time_v: # transfer at node_v\n",
    "                if (not cur_best) or time > cur_best[0]:\n",
    "                    return (time, v, route_id, dur, [u, v]) \n",
    "        \n",
    "        # In any other case no update can be made\n",
    "        return None\n",
    "                \n",
    "    def time_to_minutes(timestamp):\n",
    "        return int(timestamp[:2]) * 60 + int(timestamp[3:5])\n",
    "    \n",
    "    transfer_time = 2 # at least 2 minutes to transfer\n",
    "    max_walking_time = 10\n",
    "\n",
    "    next_transfer = {} # stores for each node u the node v \n",
    "                       # where the next transfer happens format (departure_time, v, route_id to v, duration)\n",
    "    all_roads= {}\n",
    "    end_time = time_to_minutes(end_time)\n",
    "    start_time = end_time - 120 # look only at edges departing at most 2 hours before end_time\n",
    "    \n",
    "    next_transfer[end_stop] = (end_time, end_stop, None, 0, [end_stop])\n",
    "    all_roads[end_stop] = [(end_time, end_stop, None, 0)]\n",
    "\n",
    "    edges = edges.filter(F.col('start_time').between(start_time, end_time)).toPandas().sort_values(by=['start_time'], ascending=False).to_numpy()\n",
    "\n",
    "    for row in edges:\n",
    "        \n",
    "        start_vertex, end_vertex, start, duration, route_id = row[:5]\n",
    "        \n",
    "        update = edge_valid(start_vertex, end_vertex, start, duration, route_id)\n",
    "        if update:\n",
    "            if(all_roads.get(start_vertex)!= None):    \n",
    "                all_roads[start_vertex].append(update)\n",
    "            elif (all_roads.get(start_vertex)== None):\n",
    "                all_roads[start_vertex]= [update]\n",
    "                \n",
    "            next_transfer[start_vertex] = update\n",
    "                    \n",
    "            w_start_vertex = start_vertex\n",
    "            for w_end_vertex in inward_walking_edges.get(w_start_vertex, []):\n",
    "                duration = walking_edge_duration[(w_start_vertex, w_end_vertex)]\n",
    "                w_start = start \n",
    "                update = edge_valid(w_start_vertex, w_end_vertex, w_start, duration, 'walking')\n",
    "                if update:\n",
    "                    if(all_roads.get(w_start_vertex)!= None):\n",
    "                        all_roads[w_start_vertex].append(update)\n",
    "                    elif (all_roads.get(start_vertex)== None):\n",
    "                        all_roads[w_start_vertex]= [update]\n",
    "                    \n",
    "                    next_transfer[w_start_vertex] = update\n",
    "    \n",
    "    schema = StructType([\n",
    "        StructField(\"start_vertex\", StringType(), True),\n",
    "        StructField(\"departure_time\", StringType(), True),\n",
    "        StructField(\"end_vertex\", StringType(), True),\n",
    "        StructField(\"route_id\", StringType(), True),\n",
    "        StructField(\"duration\", IntegerType(), True),\n",
    "        StructField(\"stop_seq\", ArrayType(StringType()), True)\n",
    "    ])\n",
    "    \n",
    "    next_transfer_df = spark.createDataFrame([(key,) + value for key, value in next_transfer.items()], schema)\n",
    "\n",
    "    return next_transfer_df, all_roads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.59393000603"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "next_transfer_df, all_roads = latest_departure_paths(edges, '8591221', '20:00', inward_walking_edges, walking_edge_duration)\n",
    "end = time.time() \n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "An error was encountered:\n",
      "need more than 4 values to unpack\n",
      "Traceback (most recent call last):\n",
      "  File \"<stdin>\", line 51, in generate_best_k_paths\n",
      "ValueError: need more than 4 values to unpack\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# This cell is for generating best k paths\n",
    "def minutes_to_timestamp(minutes):\n",
    "    return str(minutes // 60) + ':' + str(minutes % 60).zfill(2)\n",
    "\n",
    "stop_id_to_stop = stops.select('stop_id', 'stop_name')\n",
    "stop_id_to_stop_dict = stop_id_to_stop.toPandas().set_index('stop_id').to_dict()['stop_name']\n",
    "route_id_to_route_name = routes.withColumn('route_name', F.concat(F.col('route_desc'), F.lit(' '), F.col('route_short_name')))\\\n",
    "                               .select('route_id', 'route_desc', 'route_short_name', 'route_name')\n",
    "route_id_to_route_name_dict = route_id_to_route_name.toPandas().set_index('route_id').to_dict()['route_name']\n",
    "route_id_to_route_name_dict['walking'] = 'walk'\n",
    "\n",
    "def select_next(time, paths_from_next_stop):\n",
    "    rev= paths_from_next_stop[::-1]\n",
    "    \n",
    "    for i in rev:\n",
    "        if (i[0]>=time):\n",
    "            return i\n",
    "    \n",
    "    return (None, None, None, None , [])\n",
    "\n",
    "def generate_best_k_paths(k_paths, start_stop, k):\n",
    "    l= k_paths[start_stop]\n",
    "    nbre_paths= k\n",
    "    if (l== None):\n",
    "        print(\"Sorry bro, no paths available\")\n",
    "        return\n",
    "    if(len(l)<k):\n",
    "        nbre_paths= len(l)\n",
    "    \n",
    "    \n",
    "    possible= l[::-1][0:nbre_paths]\n",
    "    roads= []\n",
    "    for i in possible: \n",
    "        time, next_stop, route_id, duration, stops = i\n",
    "        journey = []\n",
    "        while next_stop != start_stop:\n",
    "            journey.append(\n",
    "            (minutes_to_timestamp(time),\n",
    "             stop_id_to_stop_dict[start_stop], \n",
    "             route_id_to_route_name_dict[route_id],\n",
    "             duration,\n",
    "             minutes_to_timestamp(time + duration),\n",
    "             stop_id_to_stop_dict[next_stop])\n",
    "            )\n",
    "        \n",
    "            start_stop = next_stop\n",
    "            paths_from_next_stop = k_paths[next_stop]\n",
    "            m= select_next(time+duration, paths_from_next_stop) \n",
    "            if (m[0]!= None):\n",
    "                time, next_stop, route_id, duration, stops= m\n",
    "        \n",
    "        roads.append(journey)\n",
    "        \n",
    "    return roads\n",
    "\n",
    "def pretty_print_journey(journey):\n",
    "    if journey== None:\n",
    "        return \"No possible second best path\"\n",
    "    journey_str = '\\n'.join([\"%s : %s\\n|\\n| %s (%s min)\\n|\\n%s : %s\\n\" % segment for segment in journey])\n",
    "    return journey_str\n",
    "\n",
    "g= generate_best_k_paths(all_roads,'8591250', 4 )\n",
    "for i in g:\n",
    "    print(pretty_print_journey(i))\n",
    "    print(\"**************************\")        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "m = all_roads['8591250']\n",
    "time, next_stop, route_id, duration, stops= select_next(4, m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'8591250', u'8591118']"
     ]
    }
   ],
   "source": [
    "stops"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Send to local"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Send transfer dataframe to local"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%spark -o next_transfer_df -n -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%local\n",
    "next_transfer_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reconstruct a dict for transfers to keep old code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%local\n",
    "next_transfer = {e[0]: tuple(e[1:]) for e in next_transfer_df.to_numpy()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Send route id to route name mapping to local"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%spark -o route_id_to_route_name -n -1\n",
    "route_id_to_route_name = routes.withColumn('route_name', F.concat(F.col('route_desc'), F.lit(' '), F.col('route_short_name')))\\\n",
    "                               .select('route_id', 'route_desc', 'route_short_name', 'route_name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%local\n",
    "route_id_to_route_name_dict = route_id_to_route_name.set_index('route_id').to_dict()['route_name']\n",
    "route_id_to_route_name_dict['walking'] = 'walk'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Send stop id to stop name mapping to local"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%spark -o stop_id_to_stop -n -1\n",
    "stop_id_to_stop = stops.select('stop_id', 'stop_name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%local\n",
    "stop_id_to_stop_dict = stop_id_to_stop.set_index('stop_id').to_dict()['stop_name']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reconstruct path and pretty print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%local\n",
    "def minutes_to_timestamp(minutes):\n",
    "    return str(minutes // 60) + ':' + str(minutes % 60).zfill(2)\n",
    "    \n",
    "    \n",
    "def reconstruct_journey(next_transfer, start_stop):\n",
    "    time, next_stop, route_id, duration, stop_seq = next_transfer[start_stop]\n",
    "    journey = []\n",
    "    while next_stop != start_stop:\n",
    "        journey.append(\n",
    "            (minutes_to_timestamp(time),\n",
    "             stop_id_to_stop_dict[start_stop], \n",
    "             route_id_to_route_name_dict[route_id],\n",
    "             duration,\n",
    "             'Ride %d stops' % (len(stop_seq)-1),\n",
    "             minutes_to_timestamp(time + duration),\n",
    "             stop_id_to_stop_dict[next_stop])\n",
    "        )\n",
    "        \n",
    "        start_stop = next_stop\n",
    "        time, next_stop, route_id, duration, stop_seq = next_transfer[next_stop]\n",
    "    return journey\n",
    "\n",
    "\n",
    "def pretty_print_journey(journey):\n",
    "    journey_str = '\\n'.join([\"%s : %s\\n|\\n| %s (%s min) %s\\n|\\n%s : %s\\n\" % segment for segment in journey])\n",
    "    return journey_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%local\n",
    "print(pretty_print_journey(reconstruct_journey(next_transfer, '8590883'))) # almost same as sbb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%local\n",
    "print(pretty_print_journey(reconstruct_journey(next_transfer, '8591353'))) # almost same as sbb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%local\n",
    "print(pretty_print_journey(reconstruct_journey(next_transfer, '8590788'))) # not in sbb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%local\n",
    "print(pretty_print_journey(reconstruct_journey(next_transfer, '8591368'))) # Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark",
   "language": "python",
   "name": "pysparkkernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "python",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "pyspark",
   "pygments_lexer": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
