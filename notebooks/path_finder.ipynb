{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Path Finder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup Spark environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%local\n",
    "import os\n",
    "username = os.environ['JUPYTERHUB_USER']\n",
    "get_ipython().run_cell_magic('configure', line=\"-f\", cell='{ \"name\":\"%s-final-path-finder\", \"executorMemory\":\"4G\", \"executorCores\":4, \"numExecutors\":10, \"driverMemory\": \"4G\" }' % username)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%send_to_spark -i username -t str -n username"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql.types import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import data from HDFS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "routes = spark.read.csv('/data/sbb/csv/timetable/routes/2019/05/07/routes.csv', header=True )\n",
    "stops = spark.read.orc('/data/sbb/orc/geostops')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "walking_edges = spark.read.parquet('/user/%s/final/parquet/walking_edges' % username)\n",
    "transport_edges = spark.read.parquet('/user/%s/final/parquet/transport_edges' % username)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shortest paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "walking_edges = walking_edges.withColumn('value', F.struct(F.col('end_vertex'), F.col('duration')))\\\n",
    "                             .groupBy('start_vertex').agg({'value': 'collect_set'})\\\n",
    "                             .toPandas()\\\n",
    "                             .set_index('start_vertex')\\\n",
    "                             .to_dict()['collect_set(value)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edges = transport_edges.filter('weekday == \"monday\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function assumes a (spark) dataframe with columns 'start_vertex', 'end_vertex', 'start_time', 'duration', 'route_id' \n",
    "# edges is a dataframe that represents the edges of the graph, \n",
    "# end_time should be in the format 'HH:MM'\n",
    "def latest_departure_paths(edges, end_stop, end_time, walking_edges):\n",
    "\n",
    "    def edge_valid(u, v, time, dur, route_id): \n",
    "        next_edges = all_roads.get(v, [])\n",
    "        \n",
    "        # Did we reach the destination ?\n",
    "        if v == end_stop and time + dur <= end_time: \n",
    "             return (time, v, route_id, dur)\n",
    "        \n",
    "        if u != end_stop and v != end_stop:\n",
    "            for edge in next_edges[::-1]: # Traverse the list in reverse order because it's sorted by descending starting time\n",
    "                time_v, next_v, route_id_v, dur_v = edge\n",
    "                if (route_id == route_id_v and time + dur <= time_v) or (time + dur + transfer_time <= time_v): \n",
    "                    return (time, v, route_id, dur)            \n",
    "            \n",
    "            # Can we walk from v instead?\n",
    "            for end_vertex, walking_duration in walking_edges.get(v, []):\n",
    "                if end_vertex != u: # do not loop back to u\n",
    "                    for next_next_edge in all_roads.get(end_vertex, []):\n",
    "                        time_next = next_next_edge[0]\n",
    "                        if time + dur <= time_next - walking_duration - transfer_time : # can we make in time to v in order to walk\n",
    "                            return (time, v, route_id, dur)\n",
    "                \n",
    "        return None\n",
    "                \n",
    "    def time_to_minutes(timestamp):\n",
    "        return int(timestamp[:2]) * 60 + int(timestamp[3:5])\n",
    "    \n",
    "    \n",
    "    transfer_time = 2 # at least 2 minutes to transfer\n",
    "    \n",
    "    all_roads = {}\n",
    "    end_time = time_to_minutes(end_time)\n",
    "    start_time = end_time - 120 # look only at edges departing at most 2 hours before end_time\n",
    "        \n",
    "    edges = edges.filter(F.col('start_time').between(start_time, end_time)).toPandas().sort_values(by=['start_time'], ascending=False).to_numpy()\n",
    "\n",
    "    for row in edges:\n",
    "        start_vertex, end_vertex, start, duration, route_id = row[:5]\n",
    "        update = edge_valid(start_vertex, end_vertex, start, duration, route_id)\n",
    "        if update:\n",
    "            if start_vertex in all_roads:    \n",
    "                all_roads[start_vertex].append(update)\n",
    "            else:\n",
    "                all_roads[start_vertex] = [update]\n",
    "                        \n",
    "    return all_roads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import groupby\n",
    "import numpy as np\n",
    "\n",
    "# Journey reconstruction\n",
    "\n",
    "\n",
    "# Returns a List of all possible edges that can be taken after edge 'edge'\n",
    "def select_next(all_roads, walking_edges, edge, transfer_time=2):\n",
    "    \n",
    "    prev_time, node, prev_route_id, prev_duration = edge[:4]\n",
    "    next_edges = all_roads.get(node, [])\n",
    "    \n",
    "    if prev_route_id == 'Walking': \n",
    "        # A walking edge encodes only one next trip at the node, stored as an index of the trip in all_roads[node] \n",
    "        return [next_edges[edge[-1]]]\n",
    "    else:\n",
    "        possible_edges = []\n",
    "        # We may take a transport edge or a walking edge in this case\n",
    "        next_edges = next_edges +  get_walking_edges(all_roads, walking_edges, node)\n",
    "        for edge_n in next_edges:\n",
    "            t, v, route_id, dur = edge_n[:4]\n",
    "            if (prev_route_id == route_id or route_id == 'Walking') and prev_time + prev_duration <= t:\n",
    "                possible_edges.append(edge_n)\n",
    "            elif prev_route_id != route_id and prev_time + prev_duration + transfer_time <= t:\n",
    "                possible_edges.append(edge_n)\n",
    "\n",
    "        return possible_edges \n",
    "\n",
    "# Recursively iterate on all possible paths to the destination, and yield journeys as we find them \n",
    "def iterate_all_edges(all_roads, walking_edges, start_edges, end_stop, end_time, cur_journey):\n",
    "    for edge in start_edges:\n",
    "        t, v, route_id, dur = edge[:4]\n",
    "        if v == end_stop and t + dur <= end_time: # have we reached the destination?\n",
    "            yield cur_journey + [edge]\n",
    "        elif v != end_stop:\n",
    "            next_edges = select_next(all_roads, walking_edges, edge)\n",
    "            for journey in iterate_all_edges(all_roads, walking_edges, next_edges, end_stop, end_time, cur_journey + [edge]):\n",
    "                yield journey\n",
    "                \n",
    "# Compute the number of transfers as well as the total walking duration for a Journey\n",
    "def get_journey_attributes(journey):\n",
    "    walking_distance = sum([t[-2] for t in journey if t[2] == 'Walking'])\n",
    "    transfers = len(set([t[2] for t in journey if t[2] != 'Walking']))\n",
    "    return [transfers, walking_distance]\n",
    "\n",
    "# Compute viable walks starting at node start_stop\n",
    "# A walking edge u -> v holds information about the single trip to take from v\n",
    "# This avoids unnecessary path computations\n",
    "def get_walking_edges(all_roads, walking_edges, start_stop, transfer_time=2):\n",
    "    possible_walking_edges = []\n",
    "    for end_vertex, duration in walking_edges.get(start_stop, []):\n",
    "        for index, edge in enumerate(all_roads.get(end_vertex, [])):\n",
    "            time_next, node_next = edge[:2]\n",
    "            if node_next != start_stop:\n",
    "                possible_walking_edges.append((time_next - duration - transfer_time, end_vertex, 'Walking', duration, index))\n",
    "    return possible_walking_edges\n",
    "    \n",
    "def generate_best_paths(all_roads, walking_edges, start_stop, end_stop, end_time):\n",
    "    # add possible paths that start by walking\n",
    "    start_edges = all_roads.get(start_stop, []) + get_walking_edges(all_roads, walking_edges, start_stop)\n",
    "    if not start_edges: # not paths were found\n",
    "        yield []\n",
    "    else:\n",
    "        # sort edges and group by start_time\n",
    "        start_edges = sorted(start_edges, key=lambda x:x[0], reverse=True)\n",
    "        start_edges = groupby(start_edges, key=lambda x:x[0])\n",
    "        for start_time, edges in start_edges:\n",
    "            # find all possible journeys that start at time start_time\n",
    "            all_journeys = list(iterate_all_edges(all_roads, walking_edges, list(edges), end_stop, end_time, []))\n",
    "            journey_attribs = np.array([get_journey_attributes(journey) for journey in all_journeys])\n",
    "            sorted_indices = np.lexsort(journey_attribs.T)\n",
    "            for i in sorted_indices:\n",
    "                yield all_journeys[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Processes a list of edges (Journey) into a list of segments\n",
    "def journey_to_segments (journey, start_stop):\n",
    "    \n",
    "    grouped_journey = [(route_id, list(edges)) for (route_id, edges) in  groupby(journey, lambda x: x[2])]\n",
    "    segments = []\n",
    "    for index, (route_id, edges) in enumerate(grouped_journey):\n",
    "        \n",
    "        start_time_s = edges[0][0]\n",
    "        \n",
    "        if route_id == 'Walking' and index > 0:\n",
    "            # Start walking as soon as you get to the previous stop\n",
    "            start_time_s = segments[-1][4] + segments[-1][5]\n",
    "             \n",
    "        end_stop_s = edges[-1][1]\n",
    "        duration_s = edges[-1][0] + edges[-1][3] - edges[0][0]\n",
    "        \n",
    "        start_stop_s = start_stop if index == 0 else edges[0][1]\n",
    "        \n",
    "        if index > 0 and segments[-1][3] == 'Walking':\n",
    "            start_stop_s = segments[-1][2]\n",
    "        \n",
    "        stops_s = [t[1] for t in edges]\n",
    "        \n",
    "        if start_stop_s != stops_s[0]:\n",
    "            stops_s = [start_stop_s] + stops_s\n",
    "        \n",
    "        segments.append((index + 1, start_stop_s, end_stop_s, route_id, start_time_s, duration_s, stops_s))\n",
    "            \n",
    "    return segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def journey_to_df(journey_list):\n",
    "    arr = []\n",
    "    journey_number = 0\n",
    "    for journey in journey_list:\n",
    "        journey_number += 1\n",
    "        arr = arr + [(journey_number,) + seg for seg in journey]\n",
    "    \n",
    "    schema = StructType([\n",
    "        StructField(\"journey_number\", IntegerType(), True),\n",
    "        StructField(\"segment_number\", IntegerType(), True),\n",
    "        StructField(\"start_vertex\", StringType(), True),\n",
    "        StructField(\"end_vertex\", StringType(), True),\n",
    "        StructField(\"route_id\", StringType(), True),\n",
    "        StructField(\"departure_time\", StringType(), True),\n",
    "        StructField(\"duration\", StringType(), True),\n",
    "        StructField(\"stop_seq\", ArrayType(StringType()), True)\n",
    "    ])\n",
    "    \n",
    "    journey_df = spark.createDataFrame(arr, schema)\n",
    "    \n",
    "    return journey_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_id_to_stop = stops.select('stop_id', 'stop_name')\n",
    "stop_id_to_stop_dict = stop_id_to_stop.toPandas().set_index('stop_id').to_dict()['stop_name']\n",
    "\n",
    "route_id_to_route_name = routes.withColumn('route_name', F.concat(F.col('route_desc'), F.lit(' '), F.col('route_short_name')))\\\n",
    "                               .select('route_id', 'route_desc', 'route_short_name', 'route_name')\n",
    "route_id_to_route_name_dict = route_id_to_route_name.toPandas().set_index('route_id').to_dict()['route_name']\n",
    "route_id_to_route_name_dict['Walking'] = 'Walk'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def minutes_to_timestamp(minutes):\n",
    "    return str(minutes // 60) + ':' + str(minutes % 60).zfill(2)\n",
    "\n",
    "def pretty_print_journey(journey):\n",
    "    journey_str = '\\n'.join([\"%s : %s\\n|\\n| %s (%s min)\\n| %s\\n|\\n%s : %s\\n\" % (minutes_to_timestamp(time), \n",
    "                                                                             stop_id_to_stop_dict[start],\n",
    "                                                                             route_id_to_route_name_dict[route_id],\n",
    "                                                                             minutes_to_timestamp(duration),\n",
    "                                                                             ' -> '.join([stop_id_to_stop_dict[s] for s in stops]) if route_id != 'Walking' else '',\n",
    "                                                                             minutes_to_timestamp(time + duration),\n",
    "                                                                             stop_id_to_stop_dict[end]) for _, start, end, route_id, time, duration, stops in journey])\n",
    "    return journey_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "end_stop = '8591221'\n",
    "import time\n",
    "start = time.time()\n",
    "all_roads = latest_departure_paths(edges, end_stop , '20:00', walking_edges)\n",
    "end = time.time() \n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_roads.keys()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "journey = next(generate_best_paths(all_roads, walking_edges, all_roads.keys()[0], end_stop, 20 * 60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pretty_print_journey(journey_to_segments(journey, all_roads.keys()[0])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate 5 journeys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "journey_list = []\n",
    "generator = generate_best_paths(all_roads, walking_edges, all_roads.keys()[0], end_stop, 20 * 60)\n",
    "for _ in range(5):\n",
    "    journey = next(generator)\n",
    "    journey_list.append(journey_to_segments(journey, all_roads.keys()[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "journey_df = journey_to_df(journey_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Send to local"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%spark -o journey_df -n -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%local\n",
    "journey_df['start_vertex'] = journey_df.start_vertex.astype(str)\n",
    "journey_df['end_vertex'] = journey_df.end_vertex.astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%spark -o stop_id_to_stop -n -1\n",
    "stop_id_to_stop = stops.select('stop_id', 'stop_name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%spark -o stop_id_to_lon -n -1\n",
    "stop_id_to_lon = stops.select('stop_id', 'stop_lon')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%spark -o stop_id_to_lat -n -1\n",
    "stop_id_to_lat = stops.select('stop_id', 'stop_lat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%spark -o route_id_to_route_name -n -1\n",
    "route_id_to_route_name = routes.withColumn('route_name', F.concat(F.col('route_desc'), F.lit(' '), F.col('route_short_name')))\\\n",
    "                               .select('route_id', 'route_desc', 'route_short_name', 'route_name')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Display results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%local\n",
    "stop_id_to_stop_dict = stop_id_to_stop.set_index('stop_id').to_dict()['stop_name']\n",
    "\n",
    "stop_id_to_lon_dict = stop_id_to_lon.set_index('stop_id').to_dict()['stop_lon']\n",
    "stop_id_to_lat_dict = stop_id_to_lat.set_index('stop_id').to_dict()['stop_lat']\n",
    "\n",
    "route_id_to_route_name_dict = route_id_to_route_name.set_index('route_id').to_dict()['route_name']\n",
    "route_id_to_route_name_dict['Walking'] = 'Walk'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%local\n",
    "def minutes_to_timestamp(minutes):\n",
    "    if minutes < 60:\n",
    "        return str(minutes)\n",
    "    return str(minutes // 60) + ':' + str(minutes % 60).zfill(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%local\n",
    "def minutes_to_duration(minutes):\n",
    "    if minutes < 60:\n",
    "        return str(minutes) + ' min'\n",
    "    return str(minutes // 60) + ' hr ' + str(minutes % 60) + ' min'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%local\n",
    "def pretty_print_journey(journey):\n",
    "    journey_str = '\\n'.join([\"%s : %s\\n|\\n| %s (%s min)\\n| %s\\n|\\n%s : %s\\n\" % (minutes_to_timestamp(time), \n",
    "                                                                             stop_id_to_stop_dict[start],\n",
    "                                                                             route_id_to_route_name_dict[route_id],\n",
    "                                                                             minutes_to_timestamp(duration),\n",
    "                                                                             ' -> '.join([stop_id_to_stop_dict[s] for s in stops]) if route_id != 'Walking' else '',\n",
    "                                                                             minutes_to_timestamp(time + duration),\n",
    "                                                                             stop_id_to_stop_dict[end]) for _, start, end, route_id, time, duration, stops in journey])\n",
    "    return journey_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%local\n",
    "def journeys_to_str(df):\n",
    "    if len(df) == 0:\n",
    "        return \"No possible path\"\n",
    "    \n",
    "    n = df['journey_number'].unique()\n",
    "\n",
    "    res = []\n",
    "    for i in sorted(n):\n",
    "        segment_list = sorted(df[df.journey_number == i].values[:,1:], key = lambda e: e[0])\n",
    "        res.append(pretty_print_journey(segment_list))\n",
    "    return '\\n******************************\\n'.join(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%local\n",
    "print(journeys_to_str(journey_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Map visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%local\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def get_cmap(n, name='hsv'):\n",
    "    '''Returns a function that maps each index in 0, 1, ..., n-1 to a distinct \n",
    "    RGB color; the keyword argument name must be a standard mpl colormap name.'''\n",
    "    return plt.cm.get_cmap(name, n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%local\n",
    "import plotly.graph_objects as go\n",
    "from matplotlib.colors import rgb2hex\n",
    "from ipywidgets import interact\n",
    "\n",
    "def map_plot():\n",
    "    fig = go.Figure()\n",
    "\n",
    "    fig.add_trace(go.Scattermapbox(\n",
    "    ))\n",
    "\n",
    "    fig.update_layout(\n",
    "        autosize=True,\n",
    "        hovermode='closest',\n",
    "        mapbox=dict(\n",
    "            style='carto-positron',\n",
    "            # style='open-street-map',\n",
    "            bearing=0,\n",
    "            pitch=0,\n",
    "            zoom=11\n",
    "        ),\n",
    "        height=900,\n",
    "        width=1200\n",
    "    )\n",
    "\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%local\n",
    "\n",
    "fig = map_plot()\n",
    "stream_fig = go.FigureWidget(fig)\n",
    "stream_data = stream_fig.data\n",
    "\n",
    "@interact(Journey=journey_df.journey_number.unique())\n",
    "def show_path(Journey):\n",
    "    df=journey_df\n",
    "\n",
    "    if len(df) == 0:\n",
    "        return\n",
    "\n",
    "    n = df['journey_number'].unique()\n",
    "\n",
    "    journey = sorted(df[df.journey_number == Journey].values[:,1:], key = lambda e: e[0])        \n",
    "    \n",
    "    departure_time = journey[0][4]\n",
    "    arrival_time = journey[-1][4] + journey[-1][5]\n",
    "    \n",
    "    stops_per_segment = [seg[-1] for seg in journey]\n",
    "    \n",
    "    stops_per_segment_no_duplicates = [stops_per_segment[0]] + [ss[1:] for ss in stops_per_segment[1:]]\n",
    "\n",
    "    stops = [item for sublist in stops_per_segment_no_duplicates for item in sublist]\n",
    "    \n",
    "    lats = [stop_id_to_lat_dict[s] for s in stops]\n",
    "    lons = [stop_id_to_lon_dict[s] for s in stops]\n",
    "    \n",
    "    # Reset figure and center figure\n",
    "    with stream_fig.batch_update():\n",
    "        stream_fig.data = stream_fig.data[:1]\n",
    "        stream_fig.update_layout(mapbox_center=dict(lat = (max(lats)+min(lats))/2, lon = (max(lons)+min(lons))/2))\n",
    "        stream_fig.update_layout(legend_traceorder=\"reversed\", legend_valign='top')\n",
    "        stream_fig.update_layout(title_text='%s (%s) -> %s (%s)' % (stop_id_to_stop_dict[stops[0]],\n",
    "                                                                    minutes_to_timestamp(departure_time),\n",
    "                                                                    stop_id_to_stop_dict[stops[-1]],\n",
    "                                                                    minutes_to_timestamp(arrival_time)))\n",
    "    \n",
    "    \n",
    "    stops_per_route = [(seg[3], seg[4], seg[5], seg[-1]) for seg in journey]\n",
    "    \n",
    "    for route_id, time, duration, stops in reversed(stops_per_route):\n",
    "        stop_names = [stop_id_to_stop_dict[s] for s in stops]\n",
    "        \n",
    "        trace_name = '<b>' + route_id_to_route_name_dict[route_id] + '</b><br>%s %s<br>%s' % (stop_names[0],\n",
    "                                                                                              minutes_to_timestamp(time),\n",
    "                                                                                              minutes_to_duration(duration))\n",
    "        \n",
    "        if route_id != 'Walking':\n",
    "            trace_name += ' (%d stops)' % (len(stops)-1)\n",
    "        trace_name += '<br>%s %s' % (stop_names[-1], minutes_to_timestamp(time + duration))\n",
    "        \n",
    "        with stream_fig.batch_update():\n",
    "            stream_fig.add_trace(go.Scattermapbox(\n",
    "                lat=[stop_id_to_lat_dict[s] for s in stops],\n",
    "                lon=[stop_id_to_lon_dict[s] for s in stops],\n",
    "                mode='lines+markers',\n",
    "                marker=go.scattermapbox.Marker(\n",
    "                    size=6,\n",
    "                ),\n",
    "                opacity=1,\n",
    "                hovertext=stop_names,\n",
    "                name=trace_name,\n",
    "                hoverinfo=\"text+name\",\n",
    "                hoverlabel_namelength=-1\n",
    "            ))\n",
    "        \n",
    "stream_fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark",
   "language": "python",
   "name": "pysparkkernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "python",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "pyspark",
   "pygments_lexer": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
